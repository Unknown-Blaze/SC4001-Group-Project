{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdfc293c",
   "metadata": {},
   "source": [
    "# Notebook 2: Model Training & Hyperparameter Optimization\n",
    "## Method A - Sentiment Analysis with Domain Adaptation\n",
    "\n",
    "### Objectives:\n",
    "1. Train TF-IDF + FFNN classifier\n",
    "2. Train E5/MiniLM embedding classifier\n",
    "3. Fine-tune BERT for sentiment analysis\n",
    "4. Hyperparameter optimization with Optuna\n",
    "5. Save best models for evaluation\n",
    "\n",
    "### Models to Train:\n",
    "- **Model 1**: TF-IDF features + Feed-Forward Neural Network\n",
    "- **Model 2**: E5/MiniLM embeddings + Classifier head\n",
    "- **Model 3**: BERT fine-tuning (bert-base-uncased)\n",
    "\n",
    "### Training Strategy:\n",
    "- Train on: IMDB + Yelp combined (multi-domain)\n",
    "- Validate on: IMDB + Yelp validation split\n",
    "- Test on: Amazon (cross-domain) - in Notebook 3\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d9184f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: transformers in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (4.46.3)\n",
      "Requirement already satisfied: transformers in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (4.46.3)\n",
      "Requirement already satisfied: sentence-transformers in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (3.2.1)\n",
      "Requirement already satisfied: scikit-learn in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: sentence-transformers in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (3.2.1)\n",
      "Requirement already satisfied: scikit-learn in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: optuna in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (4.5.0)\n",
      "Requirement already satisfied: optuna in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (4.5.0)\n",
      "Requirement already satisfied: tqdm in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (4.67.1)\n",
      "Requirement already satisfied: tqdm in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: pandas in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (1.24.4)\n",
      "Requirement already satisfied: pandas in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: sympy in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: sympy in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: networkx in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: jinja2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: triton==3.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version < \"3.13\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (3.0.0)\n",
      "Requirement already satisfied: filelock in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: filelock in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: fsspec in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: fsspec in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: requests in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: requests in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: scipy in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: Pillow in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: scipy in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: Pillow in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: colorlog in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: colorlog in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from optuna) (2.0.44)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from optuna) (2.0.44)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (12.9.86)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch) (12.9.86)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3; platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"arm64\" or platform_machine == \"aarch64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3; platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"arm64\" or platform_machine == \"aarch64\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: Mako in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (6.4.5)\n",
      "Requirement already satisfied: Mako in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (6.4.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (8.5.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (8.5.0)\n",
      "Requirement already satisfied: greenlet>=1; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from importlib-resources; python_version < \"3.9\"->alembic>=1.5.0->optuna) (3.20.2)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages (from importlib-resources; python_version < \"3.9\"->alembic>=1.5.0->optuna) (3.20.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# Run this cell only once\n",
    "%pip install torch transformers sentence-transformers scikit-learn optuna tqdm numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8e5cdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Core libraries loaded\n"
     ]
    }
   ],
   "source": [
    "## Setup & Imports - Part 1: Core Libraries\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"✓ Core libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0685486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PyTorch... (this may take 30-60 seconds)\n",
      "✓ PyTorch loaded (version: 2.4.1+cu121)\n",
      "  CUDA available: True\n",
      "  GPU: NVIDIA A100 80GB PCIe\n",
      "✓ PyTorch loaded (version: 2.4.1+cu121)\n",
      "  CUDA available: True\n",
      "  GPU: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "## Setup & Imports - Part 2: PyTorch & Deep Learning\n",
    "print(\"Loading PyTorch... (this may take 30-60 seconds)\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(f\"✓ PyTorch loaded (version: {torch.__version__})\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da2c193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ K-Fold CV imports loaded\n"
     ]
    }
   ],
   "source": [
    "## Additional imports for K-Fold Cross-Validation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import copy\n",
    "\n",
    "print(\"✓ K-Fold CV imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a7bddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Transformers library... (this may take 30-60 seconds)\n",
      "✓ Transformers library loaded\n",
      "✓ Transformers library loaded\n"
     ]
    }
   ],
   "source": [
    "## Setup & Imports - Part 3: Transformers & Embeddings\n",
    "print(\"Loading Transformers library... (this may take 30-60 seconds)\")\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainerCallback\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"✓ Transformers library loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e545bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Scikit-learn and Optuna loaded\n"
     ]
    }
   ],
   "source": [
    "## Setup & Imports - Part 4: Scikit-learn & Optuna\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "print(\"✓ Scikit-learn and Optuna loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49832007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seed set to 42\n",
      "Using device: cuda\n",
      "✓ Setup complete\n",
      "  Working directory: /home3/rudrapra001/FYP-Research/export_package/fine_tuning\n",
      "  Data directory (shared): /home3/rudrapra001/FYP-Research/export_package/fine_tuning/../data/processed\n",
      "  Models directory (local): /home3/rudrapra001/FYP-Research/export_package/fine_tuning/models\n",
      "  Max length: 256\n",
      "  Optuna trials: 10\n",
      "  K-fold splits: 3\n"
     ]
    }
   ],
   "source": [
    "## Configuration & Setup\n",
    "\n",
    "# Set random seeds for reproducibility (matching LoRA approach)\n",
    "SEED = 42\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility across all libraries.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    print(f\"✓ Random seed set to {seed}\")\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Directory configuration\n",
    "# Data: shared with LoRA (../data/)\n",
    "# Models: local to fine_tuning/\n",
    "DATA_DIR = Path('../data/processed')  # Shared data\n",
    "MODELS_DIR = Path('models')           # Local models\n",
    "LOGS_DIR = Path('outputs/logs')       # Local logs\n",
    "\n",
    "# Create directories\n",
    "(MODELS_DIR / 'tfidf_ffnn').mkdir(parents=True, exist_ok=True)\n",
    "(MODELS_DIR / 'e5_classifier').mkdir(parents=True, exist_ok=True)\n",
    "(MODELS_DIR / 'bert_finetuned').mkdir(parents=True, exist_ok=True)\n",
    "LOGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Training configuration (matching LoRA)\n",
    "MAX_LENGTH = 256  # Token limit\n",
    "N_TRIALS = 10     # Optuna trials\n",
    "N_SPLITS = 3      # K-fold splits\n",
    "\n",
    "print(\"✓ Setup complete\")\n",
    "print(f\"  Working directory: {os.getcwd()}\")\n",
    "print(f\"  Data directory (shared): {DATA_DIR.absolute()}\")\n",
    "print(f\"  Models directory (local): {MODELS_DIR.absolute()}\")\n",
    "print(f\"  Max length: {MAX_LENGTH}\")\n",
    "print(f\"  Optuna trials: {N_TRIALS}\")\n",
    "print(f\"  K-fold splits: {N_SPLITS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8811bd",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Load Processed Data\n",
    "\n",
    "Load the preprocessed datasets from Notebook 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "690b1647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets from ../data/processed/...\n",
      "\n",
      "✓ Datasets loaded:\n",
      "  Train: 48,000 samples (IMDB + Yelp)\n",
      "  Eval:  12,000 samples (IMDB + Yelp)\n",
      "\n",
      "✓ Data extracted and ready for training\n",
      "  Train samples: 48,000\n",
      "  Eval samples:  12,000\n",
      "\n",
      "✓ Datasets loaded:\n",
      "  Train: 48,000 samples (IMDB + Yelp)\n",
      "  Eval:  12,000 samples (IMDB + Yelp)\n",
      "\n",
      "✓ Data extracted and ready for training\n",
      "  Train samples: 48,000\n",
      "  Eval samples:  12,000\n"
     ]
    }
   ],
   "source": [
    "## 1.1: Load Processed Data\n",
    "\n",
    "def load_json_data(filepath):\n",
    "    \"\"\"Load JSON dataset\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "print(\"Loading datasets from ../data/processed/...\")\n",
    "\n",
    "# Load datasets created by first.ipynb (shared data directory)\n",
    "train_data = load_json_data(DATA_DIR / 'train.json')\n",
    "val_data = load_json_data(DATA_DIR / 'eval.json')\n",
    "\n",
    "# Load summary\n",
    "summary = load_json_data(DATA_DIR / 'dataset_summary.json')\n",
    "\n",
    "print(f\"\\n✓ Datasets loaded:\")\n",
    "print(f\"  Train: {len(train_data):,} samples (IMDB + Yelp)\")\n",
    "print(f\"  Eval:  {len(val_data):,} samples (IMDB + Yelp)\")\n",
    "\n",
    "# Extract texts and labels\n",
    "train_texts = [item['text'] for item in train_data]\n",
    "train_labels = [item['label'] for item in train_data]\n",
    "\n",
    "val_texts = [item['text'] for item in val_data]\n",
    "val_labels = [item['label'] for item in val_data]\n",
    "\n",
    "print(\"\\n✓ Data extracted and ready for training\")\n",
    "print(f\"  Train samples: {len(train_texts):,}\")\n",
    "print(f\"  Eval samples:  {len(val_texts):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1a46d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training label distribution:\n",
      "  Negative: 24,030 (50.1%)\n",
      "  Positive: 23,970 (49.9%)\n",
      "\n",
      "Validation label distribution:\n",
      "  Negative: 5,970 (49.8%)\n",
      "  Positive: 6,030 (50.2%)\n"
     ]
    }
   ],
   "source": [
    "## 1.2: Data Statistics\n",
    "\n",
    "def print_label_distribution(labels, name):\n",
    "    \"\"\"Print label distribution\"\"\"\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"\\n{name} label distribution:\")\n",
    "    for label, count in zip(unique, counts):\n",
    "        sentiment = 'Positive' if label == 1 else 'Negative'\n",
    "        print(f\"  {sentiment}: {count:,} ({count/len(labels)*100:.1f}%)\")\n",
    "\n",
    "print_label_distribution(train_labels, \"Training\")\n",
    "print_label_distribution(val_labels, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6704e4",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Model 1 - TF-IDF + Feed-Forward Neural Network\n",
    "\n",
    "Classic approach: Convert text to TF-IDF features, then train a neural network.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1086bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TF-IDF features...\n",
      "This may take 2-3 minutes...\n",
      "\n",
      "✓ TF-IDF features created:\n",
      "  Train shape: (48000, 10000)\n",
      "  Val shape:   (12000, 10000)\n",
      "  Vocabulary size: 10,000\n",
      "✓ TF-IDF features created:\n",
      "  Train shape: (48000, 10000)\n",
      "  Val shape:   (12000, 10000)\n",
      "  Vocabulary size: 10,000\n",
      "\n",
      "✓ TF-IDF vectorizer saved\n",
      "\n",
      "✓ TF-IDF vectorizer saved\n"
     ]
    }
   ],
   "source": [
    "## 2.1: TF-IDF Feature Extraction\n",
    "\n",
    "print(\"Creating TF-IDF features...\")\n",
    "print(\"This may take 2-3 minutes...\\n\")\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,      # Top 10k features\n",
    "    ngram_range=(1, 2),      # Unigrams and bigrams\n",
    "    min_df=5,                 # Minimum document frequency\n",
    "    max_df=0.8,               # Maximum document frequency\n",
    "    lowercase=True,\n",
    "    strip_accents='unicode',\n",
    "    stop_words='english'\n",
    ")\n",
    "\n",
    "# Fit on training data and transform\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_texts)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(val_texts)\n",
    "\n",
    "# Convert to dense arrays for PyTorch\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_val_tfidf = X_val_tfidf.toarray()\n",
    "\n",
    "print(f\"✓ TF-IDF features created:\")\n",
    "print(f\"  Train shape: {X_train_tfidf.shape}\")\n",
    "print(f\"  Val shape:   {X_val_tfidf.shape}\")\n",
    "print(f\"  Vocabulary size: {len(tfidf_vectorizer.vocabulary_):,}\")\n",
    "\n",
    "# Save vectorizer\n",
    "with open('models/tfidf_ffnn/tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "print(\"\\n✓ TF-IDF vectorizer saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e8e25e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FFNN model class defined\n"
     ]
    }
   ],
   "source": [
    "## 2.2: Define FFNN Model\n",
    "\n",
    "class FFNNClassifier(nn.Module):\n",
    "    \"\"\"Feed-Forward Neural Network for classification\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims, dropout_rate=0.3):\n",
    "        super(FFNNClassifier, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        # Hidden layers\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_dim, 2))  # Binary classification\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"✓ FFNN model class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31af8c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training function defined\n"
     ]
    }
   ],
   "source": [
    "## 2.3: FFNN Training Function\n",
    "\n",
    "def train_ffnn(model, train_loader, val_loader, optimizer, criterion, \n",
    "               num_epochs=20, patience=3, device='cpu', save_path=None):\n",
    "    \"\"\"Train FFNN with early stopping\n",
    "    \n",
    "    Args:\n",
    "        save_path: Optional path to save best model. If None, model is not saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "        for batch_X, batch_y in pbar:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_y.size(0)\n",
    "            train_correct += (predicted == batch_y).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += batch_y.size(0)\n",
    "                val_correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f}, Train Acc={train_acc:.2f}% | \"\n",
    "              f\"Val Loss={avg_val_loss:.4f}, Val Acc={val_acc:.2f}%\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model if save_path is provided\n",
    "            if save_path is not None:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                print(f\"  ✓ New best model saved to {save_path} (Val Acc: {val_acc:.2f}%)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "print(\"✓ Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e8f3ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ K-Fold CV Optuna objective function defined\n"
     ]
    }
   ],
   "source": [
    "## 2.4: Hyperparameter Optimization with Optuna + K-Fold CV\n",
    "\n",
    "def objective_ffnn_kfold(trial):\n",
    "    \"\"\"Optuna objective function for FFNN with K-Fold Cross-Validation\n",
    "    \n",
    "    Uses 3-fold stratified CV to get more robust performance estimates.\n",
    "    Returns the mean validation accuracy across all folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hyperparameters to optimize\n",
    "    hidden_dim1 = trial.suggest_int('hidden_dim1', 128, 512, step=64)\n",
    "    hidden_dim2 = trial.suggest_int('hidden_dim2', 64, 256, step=32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    print(f\"\\n[Trial {trial.number}] Testing: hidden={hidden_dim1},{hidden_dim2}, \"\n",
    "          f\"dropout={dropout_rate:.3f}, lr={learning_rate:.2e}, batch={batch_size}\")\n",
    "    \n",
    "    # K-Fold Cross-Validation setup\n",
    "    n_folds = 3\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    # Combine train and val for k-fold (we'll use test set for final evaluation)\n",
    "    X_combined = np.vstack([X_train_tfidf, X_val_tfidf])\n",
    "    y_combined = np.array(train_labels + val_labels)\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_combined, y_combined)):\n",
    "        print(f\"  Fold {fold_idx+1}/{n_folds}...\", end=\" \")\n",
    "        \n",
    "        # Split data for this fold\n",
    "        X_fold_train = X_combined[train_idx]\n",
    "        y_fold_train = y_combined[train_idx]\n",
    "        X_fold_val = X_combined[val_idx]\n",
    "        y_fold_val = y_combined[val_idx]\n",
    "        \n",
    "        # Create fresh model for this fold\n",
    "        model = FFNNClassifier(\n",
    "            input_dim=X_train_tfidf.shape[1],\n",
    "            hidden_dims=[hidden_dim1, hidden_dim2],\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_fold_train),\n",
    "            torch.LongTensor(y_fold_train)\n",
    "        )\n",
    "        val_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_fold_val),\n",
    "            torch.LongTensor(y_fold_val)\n",
    "        )\n",
    "        \n",
    "        # Use drop_last=True to avoid BatchNorm issues with single-sample batches\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=False)\n",
    "        \n",
    "        # Optimizer and loss\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Train with reduced epochs for optimization (faster tuning)\n",
    "        _, best_val_acc = train_ffnn(\n",
    "            model, train_loader, val_loader, optimizer, criterion,\n",
    "            num_epochs=10, patience=2, device=device, save_path=None\n",
    "        )\n",
    "        \n",
    "        fold_scores.append(best_val_acc)\n",
    "        print(f\"Acc={best_val_acc:.2f}%\")\n",
    "        \n",
    "        # Clean up to save memory\n",
    "        del model, optimizer, train_loader, val_loader\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # Return mean accuracy across all folds\n",
    "    mean_acc = np.mean(fold_scores)\n",
    "    std_acc = np.std(fold_scores)\n",
    "    print(f\"  → Mean CV Accuracy: {mean_acc:.2f}% (±{std_acc:.2f}%)\")\n",
    "    \n",
    "    return mean_acc\n",
    "\n",
    "print(\"✓ K-Fold CV Optuna objective function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0688e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 00:56:00,875] A new study created in memory with name: tfidf_ffnn_kfold_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting K-Fold Cross-Validation hyperparameter optimization for TF-IDF + FFNN...\n",
      "Using 3-fold CV for robust hyperparameter selection\n",
      "This will take 20-40 minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 0] Testing: hidden=256,256, dropout=0.420, lr=1.58e-03, batch=32\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:16<00:00, 74.97it/s, loss=0.3019]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3414, Train Acc=85.16% | Val Loss=0.2644, Val Acc=88.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 58.38it/s, loss=0.0799]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 58.38it/s, loss=0.0799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2230, Train Acc=90.89% | Val Loss=0.2740, Val Acc=88.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:20<00:00, 60.71it/s, loss=0.0380]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1576, Train Acc=93.95% | Val Loss=0.3164, Val Acc=88.13%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.91%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 58.57it/s, loss=0.2637]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 58.57it/s, loss=0.2637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3438, Train Acc=85.03% | Val Loss=0.2733, Val Acc=88.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 81.27it/s, loss=0.5946]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2275, Train Acc=90.72% | Val Loss=0.2729, Val Acc=88.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:22<00:00, 55.78it/s, loss=0.1538]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1643, Train Acc=93.59% | Val Loss=0.2895, Val Acc=88.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:26<00:00, 46.44it/s, loss=0.0758]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1215, Train Acc=95.38% | Val Loss=0.3108, Val Acc=88.52%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=88.94%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:28<00:00, 43.58it/s, loss=0.4328]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:28<00:00, 43.58it/s, loss=0.4328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3392, Train Acc=85.31% | Val Loss=0.2678, Val Acc=88.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 57.40it/s, loss=0.2948]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 57.40it/s, loss=0.2948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2225, Train Acc=91.06% | Val Loss=0.2778, Val Acc=88.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:16<00:00, 77.72it/s, loss=0.0551]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1620, Train Acc=93.67% | Val Loss=0.2840, Val Acc=88.45%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.83%\n",
      "  → Mean CV Accuracy: 88.89% (±0.04%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 88.8933:   7%|▋         | 1/15 [05:23<1:15:28, 323.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:01:24,319] Trial 0 finished with value: 88.89333333333333 and parameters: {'hidden_dim1': 256, 'hidden_dim2': 256, 'dropout_rate': 0.4195981825434215, 'learning_rate': 0.0015751320499779737, 'batch_size': 32}. Best is trial 0 with value: 88.89333333333333.\n",
      "\n",
      "[Trial 1] Testing: hidden=512,192, dropout=0.412, lr=1.10e-04, batch=32\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:10<00:00, 117.04it/s, loss=0.3379]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:10<00:00, 117.04it/s, loss=0.3379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3574, Train Acc=83.93% | Val Loss=0.2613, Val Acc=89.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 70.57it/s, loss=0.2438]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 70.57it/s, loss=0.2438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1951, Train Acc=92.32% | Val Loss=0.2778, Val Acc=88.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 68.66it/s, loss=0.1458]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 68.66it/s, loss=0.1458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1048, Train Acc=96.19% | Val Loss=0.3313, Val Acc=88.14%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.08%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 66.57it/s, loss=0.2792]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3546, Train Acc=83.92% | Val Loss=0.2579, Val Acc=89.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:26<00:00, 47.43it/s, loss=0.2948]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1987, Train Acc=92.25% | Val Loss=0.2683, Val Acc=89.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:22<00:00, 55.85it/s, loss=0.1170]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:22<00:00, 55.85it/s, loss=0.1170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1101, Train Acc=96.05% | Val Loss=0.3320, Val Acc=88.19%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.16%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 70.41it/s, loss=0.3179]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 70.41it/s, loss=0.3179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3564, Train Acc=83.89% | Val Loss=0.2604, Val Acc=89.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:24<00:00, 51.18it/s, loss=0.4873]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1976, Train Acc=92.22% | Val Loss=0.2763, Val Acc=88.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:22<00:00, 54.95it/s, loss=0.0393]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:22<00:00, 54.95it/s, loss=0.0393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1068, Train Acc=96.27% | Val Loss=0.3301, Val Acc=88.27%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.06%\n",
      "  → Mean CV Accuracy: 89.10% (±0.04%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 89.0983:  13%|█▎        | 2/15 [09:07<57:24, 264.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:05:08,362] Trial 1 finished with value: 89.09833333333334 and parameters: {'hidden_dim1': 512, 'hidden_dim2': 192, 'dropout_rate': 0.4124217733388137, 'learning_rate': 0.00010994335574766199, 'batch_size': 32}. Best is trial 1 with value: 89.09833333333334.\n",
      "\n",
      "[Trial 2] Testing: hidden=192,96, dropout=0.291, lr=1.12e-03, batch=128\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 75.48it/s, loss=0.3288]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 75.48it/s, loss=0.3288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3138, Train Acc=86.41% | Val Loss=0.2622, Val Acc=89.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 61.14it/s, loss=0.1747]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 61.14it/s, loss=0.1747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1676, Train Acc=93.41% | Val Loss=0.2962, Val Acc=88.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 62.46it/s, loss=0.1182]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 62.46it/s, loss=0.1182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0801, Train Acc=97.04% | Val Loss=0.3837, Val Acc=88.13%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.04%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 75.45it/s, loss=0.2491]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 75.45it/s, loss=0.2491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3129, Train Acc=86.34% | Val Loss=0.2616, Val Acc=89.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 97.23it/s, loss=0.2105] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1718, Train Acc=93.17% | Val Loss=0.2793, Val Acc=88.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:02<00:00, 113.45it/s, loss=0.2050]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:02<00:00, 113.45it/s, loss=0.2050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0791, Train Acc=97.08% | Val Loss=0.3658, Val Acc=88.25%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.16%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:02<00:00, 109.88it/s, loss=0.2489]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3140, Train Acc=86.33% | Val Loss=0.2630, Val Acc=88.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 87.05it/s, loss=0.1463]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 87.05it/s, loss=0.1463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1676, Train Acc=93.51% | Val Loss=0.2901, Val Acc=88.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 74.38it/s, loss=0.0754]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 74.38it/s, loss=0.0754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0825, Train Acc=97.00% | Val Loss=0.3750, Val Acc=88.23%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.87%\n",
      "  → Mean CV Accuracy: 89.02% (±0.12%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 89.0983:  20%|██        | 3/15 [10:01<33:45, 168.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:06:02,633] Trial 2 finished with value: 89.02333333333333 and parameters: {'hidden_dim1': 192, 'hidden_dim2': 96, 'dropout_rate': 0.2912726728878613, 'learning_rate': 0.0011207606211860567, 'batch_size': 128}. Best is trial 1 with value: 89.09833333333334.\n",
      "\n",
      "[Trial 3] Testing: hidden=128,128, dropout=0.310, lr=8.17e-04, batch=32\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 72.84it/s, loss=0.2992]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 72.84it/s, loss=0.2992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3362, Train Acc=85.11% | Val Loss=0.2657, Val Acc=89.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:23<00:00, 53.01it/s, loss=0.1541]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2151, Train Acc=91.30% | Val Loss=0.2711, Val Acc=88.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:16<00:00, 74.85it/s, loss=0.1426]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:16<00:00, 74.85it/s, loss=0.1426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1430, Train Acc=94.56% | Val Loss=0.3034, Val Acc=88.22%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.05%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 80.52it/s, loss=0.3548]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 80.52it/s, loss=0.3548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3383, Train Acc=85.14% | Val Loss=0.2673, Val Acc=88.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 57.08it/s, loss=0.3465]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2131, Train Acc=91.55% | Val Loss=0.2695, Val Acc=88.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]:   0%|          | 0/1250 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 79.85it/s, loss=0.0848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1436, Train Acc=94.45% | Val Loss=0.2987, Val Acc=88.44%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.83%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 72.50it/s, loss=0.2428]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 72.50it/s, loss=0.2428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3390, Train Acc=85.26% | Val Loss=0.2729, Val Acc=88.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:20<00:00, 60.88it/s, loss=0.2504] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2125, Train Acc=91.58% | Val Loss=0.2727, Val Acc=88.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 69.23it/s, loss=0.0803]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1447, Train Acc=94.52% | Val Loss=0.3157, Val Acc=88.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:16<00:00, 76.98it/s, loss=0.0413] \n",
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:16<00:00, 76.98it/s, loss=0.0413] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1092, Train Acc=95.89% | Val Loss=0.3413, Val Acc=88.17%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=88.64%\n",
      "  → Mean CV Accuracy: 88.84% (±0.17%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 89.0983:  27%|██▋       | 4/15 [14:01<36:04, 196.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:10:02,238] Trial 3 finished with value: 88.83666666666666 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 128, 'dropout_rate': 0.3099085529881075, 'learning_rate': 0.000816845589476017, 'batch_size': 32}. Best is trial 1 with value: 89.09833333333334.\n",
      "\n",
      "[Trial 4] Testing: hidden=384,64, dropout=0.382, lr=2.19e-04, batch=128\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 70.80it/s, loss=0.2392]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3470, Train Acc=84.45% | Val Loss=0.2574, Val Acc=89.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.51it/s, loss=0.2261]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.51it/s, loss=0.2261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1730, Train Acc=93.50% | Val Loss=0.2788, Val Acc=88.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 64.20it/s, loss=0.0552]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 64.20it/s, loss=0.0552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0750, Train Acc=97.54% | Val Loss=0.3416, Val Acc=88.47%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.13%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 63.93it/s, loss=0.2778]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 63.93it/s, loss=0.2778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3472, Train Acc=84.54% | Val Loss=0.2548, Val Acc=89.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 59.58it/s, loss=0.2018]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1681, Train Acc=93.73% | Val Loss=0.2743, Val Acc=88.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 65.27it/s, loss=0.0998]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 65.27it/s, loss=0.0998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0731, Train Acc=97.69% | Val Loss=0.3356, Val Acc=88.62%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.44%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 48.03it/s, loss=0.2801]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3488, Train Acc=84.51% | Val Loss=0.2574, Val Acc=89.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 60.09it/s, loss=0.1440]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 60.09it/s, loss=0.1440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1737, Train Acc=93.44% | Val Loss=0.2750, Val Acc=89.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 54.21it/s, loss=0.0631]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0774, Train Acc=97.65% | Val Loss=0.3345, Val Acc=88.38%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.46%\n",
      "  → Mean CV Accuracy: 89.34% (±0.15%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 89.345:  33%|███▎      | 5/15 [15:08<24:59, 149.91s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:11:09,117] Trial 4 finished with value: 89.34499999999998 and parameters: {'hidden_dim1': 384, 'hidden_dim2': 64, 'dropout_rate': 0.3822634555704315, 'learning_rate': 0.00021930485556643703, 'batch_size': 128}. Best is trial 4 with value: 89.34499999999998.\n",
      "\n",
      "[Trial 5] Testing: hidden=448,128, dropout=0.229, lr=2.34e-03, batch=128\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 59.20it/s, loss=0.3277]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3139, Train Acc=86.27% | Val Loss=0.2721, Val Acc=88.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 44.88it/s, loss=0.2014]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1640, Train Acc=93.60% | Val Loss=0.3099, Val Acc=87.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 64.41it/s, loss=0.1390]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 64.41it/s, loss=0.1390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0699, Train Acc=97.27% | Val Loss=0.4511, Val Acc=87.61%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.62%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 42.76it/s, loss=0.2349]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3111, Train Acc=86.46% | Val Loss=0.2673, Val Acc=88.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 37.50it/s, loss=0.1336]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 37.50it/s, loss=0.1336]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1605, Train Acc=93.53% | Val Loss=0.3131, Val Acc=88.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 36.21it/s, loss=0.0688]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0701, Train Acc=97.43% | Val Loss=0.4167, Val Acc=88.23%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.75%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 34.97it/s, loss=0.3587]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3096, Train Acc=86.63% | Val Loss=0.2660, Val Acc=88.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 55.48it/s, loss=0.2284]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1653, Train Acc=93.34% | Val Loss=0.2953, Val Acc=88.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 55.47it/s, loss=0.0894]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 55.47it/s, loss=0.0894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0704, Train Acc=97.42% | Val Loss=0.4036, Val Acc=87.94%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.77%\n",
      "  → Mean CV Accuracy: 88.71% (±0.07%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 89.345:  40%|████      | 6/15 [16:40<19:33, 130.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:12:41,506] Trial 5 finished with value: 88.71499999999999 and parameters: {'hidden_dim1': 448, 'hidden_dim2': 128, 'dropout_rate': 0.22930163420191518, 'learning_rate': 0.0023359635026261607, 'batch_size': 128}. Best is trial 4 with value: 89.34499999999998.\n",
      "\n",
      "[Trial 6] Testing: hidden=128,256, dropout=0.278, lr=2.11e-03, batch=128\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 53.41it/s, loss=0.3376]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3151, Train Acc=86.22% | Val Loss=0.2625, Val Acc=89.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 49.42it/s, loss=0.2540]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1837, Train Acc=92.78% | Val Loss=0.2938, Val Acc=88.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 43.96it/s, loss=0.0863]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0981, Train Acc=96.39% | Val Loss=0.3474, Val Acc=87.89%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.12%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 39.63it/s, loss=0.2382]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 39.63it/s, loss=0.2382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3204, Train Acc=85.98% | Val Loss=0.2646, Val Acc=88.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 38.69it/s, loss=0.1427]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 38.69it/s, loss=0.1427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1831, Train Acc=92.82% | Val Loss=0.2901, Val Acc=88.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 59.69it/s, loss=0.1008]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0938, Train Acc=96.53% | Val Loss=0.3666, Val Acc=88.08%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.83%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 58.61it/s, loss=0.2414]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 58.61it/s, loss=0.2414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3172, Train Acc=86.36% | Val Loss=0.2668, Val Acc=88.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 50.57it/s, loss=0.1631]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 50.57it/s, loss=0.1631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1782, Train Acc=92.85% | Val Loss=0.3042, Val Acc=88.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 51.49it/s, loss=0.1055]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0986, Train Acc=96.29% | Val Loss=0.3603, Val Acc=87.80%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.83%\n",
      "  → Mean CV Accuracy: 88.93% (±0.13%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 89.345:  47%|████▋     | 7/15 [18:02<15:16, 114.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:14:03,541] Trial 6 finished with value: 88.92999999999999 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 256, 'dropout_rate': 0.2776339944800051, 'learning_rate': 0.0021137059440645744, 'batch_size': 128}. Best is trial 4 with value: 89.34499999999998.\n",
      "\n",
      "[Trial 7] Testing: hidden=192,256, dropout=0.433, lr=7.57e-03, batch=128\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 75.93it/s, loss=0.3474]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3320, Train Acc=85.74% | Val Loss=0.2678, Val Acc=88.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 71.65it/s, loss=0.2731]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1968, Train Acc=92.27% | Val Loss=0.2745, Val Acc=88.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 60.46it/s, loss=0.1709]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 60.46it/s, loss=0.1709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1187, Train Acc=95.34% | Val Loss=0.3317, Val Acc=87.60%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.69%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 64.23it/s, loss=0.2742]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 64.23it/s, loss=0.2742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3333, Train Acc=85.79% | Val Loss=0.2723, Val Acc=88.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 53.59it/s, loss=0.3133]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 53.59it/s, loss=0.3133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1952, Train Acc=92.35% | Val Loss=0.2811, Val Acc=88.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 52.60it/s, loss=0.1054]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1181, Train Acc=95.47% | Val Loss=0.3302, Val Acc=88.02%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.80%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 62.87it/s, loss=0.2572]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 62.87it/s, loss=0.2572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3328, Train Acc=85.63% | Val Loss=0.2741, Val Acc=88.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 54.80it/s, loss=0.1575]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1954, Train Acc=92.25% | Val Loss=0.2816, Val Acc=88.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 71.90it/s, loss=0.1708]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 71.90it/s, loss=0.1708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1180, Train Acc=95.47% | Val Loss=0.3299, Val Acc=88.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 50.56it/s, loss=0.0837]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.0856, Train Acc=96.84% | Val Loss=0.4001, Val Acc=87.78%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=88.72%\n",
      "  → Mean CV Accuracy: 88.74% (±0.05%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 89.345:  53%|█████▎    | 8/15 [19:13<11:43, 100.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:15:13,928] Trial 7 finished with value: 88.73500000000001 and parameters: {'hidden_dim1': 192, 'hidden_dim2': 256, 'dropout_rate': 0.43253984700833437, 'learning_rate': 0.007568292060167618, 'batch_size': 128}. Best is trial 4 with value: 89.34499999999998.\n",
      "\n",
      "[Trial 8] Testing: hidden=128,96, dropout=0.214, lr=4.47e-04, batch=128\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 72.28it/s, loss=0.3186]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 72.28it/s, loss=0.3186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3249, Train Acc=85.81% | Val Loss=0.2573, Val Acc=89.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 65.81it/s, loss=0.1738]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1575, Train Acc=93.96% | Val Loss=0.2936, Val Acc=88.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 57.92it/s, loss=0.0346]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 57.92it/s, loss=0.0346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0707, Train Acc=97.58% | Val Loss=0.3852, Val Acc=87.92%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.08%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 39.55it/s, loss=0.2161]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 39.55it/s, loss=0.2161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3245, Train Acc=85.72% | Val Loss=0.2584, Val Acc=89.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 43.47it/s, loss=0.2001]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 43.47it/s, loss=0.2001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1602, Train Acc=93.92% | Val Loss=0.2905, Val Acc=88.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 41.94it/s, loss=0.0671]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 41.94it/s, loss=0.0671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0722, Train Acc=97.54% | Val Loss=0.3801, Val Acc=87.66%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.17%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 53.65it/s, loss=0.2899]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 53.65it/s, loss=0.2899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3227, Train Acc=85.76% | Val Loss=0.2587, Val Acc=89.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 42.99it/s, loss=0.1382]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1566, Train Acc=94.25% | Val Loss=0.2939, Val Acc=88.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 70.86it/s, loss=0.0899]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 70.86it/s, loss=0.0899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0674, Train Acc=97.74% | Val Loss=0.3905, Val Acc=87.86%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.06%\n",
      "  → Mean CV Accuracy: 89.10% (±0.05%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 89.345:  60%|██████    | 9/15 [20:34<09:26, 94.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:16:35,082] Trial 8 finished with value: 89.10166666666667 and parameters: {'hidden_dim1': 128, 'hidden_dim2': 96, 'dropout_rate': 0.21356818667316144, 'learning_rate': 0.0004473636174621269, 'batch_size': 128}. Best is trial 4 with value: 89.34499999999998.\n",
      "\n",
      "[Trial 9] Testing: hidden=256,96, dropout=0.363, lr=1.91e-04, batch=128\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 53.48it/s, loss=0.2423]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 53.48it/s, loss=0.2423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3592, Train Acc=83.63% | Val Loss=0.2540, Val Acc=89.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 40.56it/s, loss=0.1195]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 40.56it/s, loss=0.1195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1766, Train Acc=93.29% | Val Loss=0.2747, Val Acc=88.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 40.89it/s, loss=0.0909]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0860, Train Acc=97.11% | Val Loss=0.3243, Val Acc=88.24%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.34%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 37.78it/s, loss=0.4710]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 37.78it/s, loss=0.4710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3583, Train Acc=83.63% | Val Loss=0.2561, Val Acc=89.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 76.68it/s, loss=0.2371]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1767, Train Acc=93.35% | Val Loss=0.2740, Val Acc=89.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 35.74it/s, loss=0.1322]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 35.74it/s, loss=0.1322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0868, Train Acc=97.07% | Val Loss=0.3229, Val Acc=88.56%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.31%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 60.29it/s, loss=0.2524] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3556, Train Acc=83.90% | Val Loss=0.2575, Val Acc=89.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 62.31it/s, loss=0.1656]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 62.31it/s, loss=0.1656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1759, Train Acc=93.36% | Val Loss=0.2732, Val Acc=88.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 61.14it/s, loss=0.0603]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 61.14it/s, loss=0.0603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0899, Train Acc=96.95% | Val Loss=0.3243, Val Acc=88.47%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.22%\n",
      "  → Mean CV Accuracy: 89.29% (±0.05%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 89.345:  67%|██████▋   | 10/15 [21:57<07:35, 91.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:17:58,429] Trial 9 finished with value: 89.29333333333334 and parameters: {'hidden_dim1': 256, 'hidden_dim2': 96, 'dropout_rate': 0.3628088249474746, 'learning_rate': 0.00019135880487692312, 'batch_size': 128}. Best is trial 4 with value: 89.34499999999998.\n",
      "\n",
      "[Trial 10] Testing: hidden=384,64, dropout=0.491, lr=3.16e-04, batch=64\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 69.99it/s, loss=0.1695]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 69.99it/s, loss=0.1695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3473, Train Acc=84.50% | Val Loss=0.2585, Val Acc=89.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.61it/s, loss=0.1766]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.61it/s, loss=0.1766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1944, Train Acc=92.72% | Val Loss=0.2751, Val Acc=88.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 67.59it/s, loss=0.1822]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 67.59it/s, loss=0.1822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1117, Train Acc=96.00% | Val Loss=0.3342, Val Acc=88.59%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.17%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.98it/s, loss=0.2831]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.98it/s, loss=0.2831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3428, Train Acc=84.96% | Val Loss=0.2572, Val Acc=89.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 62.73it/s, loss=0.1903]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 62.73it/s, loss=0.1903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1957, Train Acc=92.33% | Val Loss=0.2709, Val Acc=89.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 66.97it/s, loss=0.1378]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 66.97it/s, loss=0.1378]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1157, Train Acc=95.80% | Val Loss=0.3242, Val Acc=88.45%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.22%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 68.04it/s, loss=0.3619]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 68.04it/s, loss=0.3619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3456, Train Acc=84.81% | Val Loss=0.2578, Val Acc=89.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:13<00:00, 46.13it/s, loss=0.2723]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1968, Train Acc=92.46% | Val Loss=0.2747, Val Acc=88.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 54.22it/s, loss=0.1784]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 54.22it/s, loss=0.1784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1158, Train Acc=95.88% | Val Loss=0.3234, Val Acc=88.62%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.21%\n",
      "  → Mean CV Accuracy: 89.20% (±0.02%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 89.345:  73%|███████▎  | 11/15 [23:55<06:36, 99.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:19:56,203] Trial 10 finished with value: 89.19666666666666 and parameters: {'hidden_dim1': 384, 'hidden_dim2': 64, 'dropout_rate': 0.4908611332363598, 'learning_rate': 0.0003156826122536684, 'batch_size': 64}. Best is trial 4 with value: 89.34499999999998.\n",
      "\n",
      "[Trial 11] Testing: hidden=320,64, dropout=0.354, lr=1.18e-04, batch=64\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 61.64it/s, loss=0.2248]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 61.64it/s, loss=0.2248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3688, Train Acc=83.51% | Val Loss=0.2573, Val Acc=89.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 53.68it/s, loss=0.1743]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 53.68it/s, loss=0.1743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1844, Train Acc=93.13% | Val Loss=0.2691, Val Acc=88.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 43.26it/s, loss=0.0569]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 43.26it/s, loss=0.0569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0920, Train Acc=96.93% | Val Loss=0.3145, Val Acc=88.58%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.55%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 53.91it/s, loss=0.1874]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 53.91it/s, loss=0.1874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3689, Train Acc=83.41% | Val Loss=0.2567, Val Acc=89.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:13<00:00, 45.75it/s, loss=0.1346]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1877, Train Acc=93.01% | Val Loss=0.2664, Val Acc=88.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 55.41it/s, loss=0.0874]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 55.41it/s, loss=0.0874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0962, Train Acc=96.80% | Val Loss=0.3154, Val Acc=88.61%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.47%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 52.93it/s, loss=0.3793]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 52.93it/s, loss=0.3793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3668, Train Acc=83.29% | Val Loss=0.2581, Val Acc=89.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 60.53it/s, loss=0.0765]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 60.53it/s, loss=0.0765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1883, Train Acc=92.88% | Val Loss=0.2664, Val Acc=89.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.67it/s, loss=0.0751]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.67it/s, loss=0.0751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0956, Train Acc=96.86% | Val Loss=0.3089, Val Acc=88.78%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.31%\n",
      "  → Mean CV Accuracy: 89.44% (±0.10%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 89.44:  80%|████████  | 12/15 [26:15<05:35, 111.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:22:16,607] Trial 11 finished with value: 89.44 and parameters: {'hidden_dim1': 320, 'hidden_dim2': 64, 'dropout_rate': 0.3535602771439335, 'learning_rate': 0.00011835846181383978, 'batch_size': 64}. Best is trial 11 with value: 89.44.\n",
      "\n",
      "[Trial 12] Testing: hidden=384,64, dropout=0.354, lr=1.15e-04, batch=64\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 68.79it/s, loss=0.1638]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 68.79it/s, loss=0.1638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3655, Train Acc=83.51% | Val Loss=0.2591, Val Acc=89.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 81.53it/s, loss=0.1341]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 81.53it/s, loss=0.1341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1885, Train Acc=92.82% | Val Loss=0.2693, Val Acc=89.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]:   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 92.18it/s, loss=0.1095] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0970, Train Acc=96.72% | Val Loss=0.3129, Val Acc=88.78%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.32%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 64.17it/s, loss=0.2393]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 64.17it/s, loss=0.2393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3641, Train Acc=83.44% | Val Loss=0.2554, Val Acc=89.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 66.71it/s, loss=0.2349]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 66.71it/s, loss=0.2349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1839, Train Acc=93.00% | Val Loss=0.2652, Val Acc=88.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.09it/s, loss=0.1022]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0893, Train Acc=97.08% | Val Loss=0.3095, Val Acc=88.58%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.53%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 57.99it/s, loss=0.2697]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3613, Train Acc=83.68% | Val Loss=0.2565, Val Acc=89.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 50.36it/s, loss=0.1164]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 50.36it/s, loss=0.1164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1848, Train Acc=93.03% | Val Loss=0.2705, Val Acc=88.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 42.57it/s, loss=0.1171]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0925, Train Acc=97.07% | Val Loss=0.3221, Val Acc=88.26%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.46%\n",
      "  → Mean CV Accuracy: 89.44% (±0.09%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 89.44:  87%|████████▋ | 13/15 [28:13<03:46, 113.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:24:14,045] Trial 12 finished with value: 89.435 and parameters: {'hidden_dim1': 384, 'hidden_dim2': 64, 'dropout_rate': 0.35410216283608925, 'learning_rate': 0.00011509651352150205, 'batch_size': 64}. Best is trial 11 with value: 89.44.\n",
      "\n",
      "[Trial 13] Testing: hidden=320,192, dropout=0.338, lr=1.04e-04, batch=64\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 58.51it/s, loss=0.2837]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3620, Train Acc=83.27% | Val Loss=0.2579, Val Acc=89.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.48it/s, loss=0.2367]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.48it/s, loss=0.2367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1811, Train Acc=92.91% | Val Loss=0.2728, Val Acc=89.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 58.62it/s, loss=0.0848]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0865, Train Acc=97.15% | Val Loss=0.3267, Val Acc=88.71%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.25%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:14<00:00, 43.87it/s, loss=0.2578]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3583, Train Acc=83.83% | Val Loss=0.2552, Val Acc=89.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 57.32it/s, loss=0.2107]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1765, Train Acc=93.23% | Val Loss=0.2722, Val Acc=88.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 50.20it/s, loss=0.0464]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 50.20it/s, loss=0.0464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0809, Train Acc=97.32% | Val Loss=0.3194, Val Acc=88.64%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.31%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 64.19it/s, loss=0.3508]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3570, Train Acc=83.70% | Val Loss=0.2591, Val Acc=89.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 73.31it/s, loss=0.1296]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 73.31it/s, loss=0.1296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1785, Train Acc=93.28% | Val Loss=0.2736, Val Acc=88.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.17it/s, loss=0.1873]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0861, Train Acc=97.15% | Val Loss=0.3352, Val Acc=88.39%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.31%\n",
      "  → Mean CV Accuracy: 89.30% (±0.03%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 89.44:  93%|█████████▎| 14/15 [30:27<01:59, 119.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:26:27,914] Trial 13 finished with value: 89.295 and parameters: {'hidden_dim1': 320, 'hidden_dim2': 192, 'dropout_rate': 0.33764300167744815, 'learning_rate': 0.00010363921055696355, 'batch_size': 64}. Best is trial 11 with value: 89.44.\n",
      "\n",
      "[Trial 14] Testing: hidden=384,64, dropout=0.339, lr=5.29e-04, batch=64\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 64.72it/s, loss=0.1959]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 64.72it/s, loss=0.1959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3224, Train Acc=85.89% | Val Loss=0.2630, Val Acc=88.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 68.77it/s, loss=0.2015]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 68.77it/s, loss=0.2015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1786, Train Acc=93.03% | Val Loss=0.2833, Val Acc=88.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 74.76it/s, loss=0.0592]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0846, Train Acc=96.98% | Val Loss=0.3875, Val Acc=88.16%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=88.92%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 81.87it/s, loss=0.1899]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 81.87it/s, loss=0.1899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3234, Train Acc=86.06% | Val Loss=0.2602, Val Acc=89.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]:   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 71.48it/s, loss=0.1754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1760, Train Acc=93.12% | Val Loss=0.2886, Val Acc=88.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.84it/s, loss=0.0668]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.84it/s, loss=0.0668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0833, Train Acc=96.93% | Val Loss=0.3756, Val Acc=88.09%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.31%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 81.34it/s, loss=0.3068]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 81.34it/s, loss=0.3068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3198, Train Acc=86.16% | Val Loss=0.2621, Val Acc=89.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 75.95it/s, loss=0.2174]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 75.95it/s, loss=0.2174]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1730, Train Acc=93.30% | Val Loss=0.2912, Val Acc=88.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 67.42it/s, loss=0.0581]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 67.42it/s, loss=0.0581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.0765, Train Acc=97.25% | Val Loss=0.4010, Val Acc=88.31%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=89.17%\n",
      "  → Mean CV Accuracy: 89.13% (±0.16%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 89.44: 100%|██████████| 15/15 [32:14<00:00, 128.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:28:15,190] Trial 14 finished with value: 89.13333333333334 and parameters: {'hidden_dim1': 384, 'hidden_dim2': 64, 'dropout_rate': 0.33865304013034375, 'learning_rate': 0.000529056994167218, 'batch_size': 64}. Best is trial 11 with value: 89.44.\n",
      "\n",
      "======================================================================\n",
      "K-FOLD CV OPTIMIZATION COMPLETE - TF-IDF + FFNN\n",
      "======================================================================\n",
      "Best mean CV accuracy: 89.44%\n",
      "\n",
      "Best hyperparameters:\n",
      "  hidden_dim1: 320\n",
      "  hidden_dim2: 64\n",
      "  dropout_rate: 0.3535602771439335\n",
      "  learning_rate: 0.00011835846181383978\n",
      "  batch_size: 64\n",
      "\n",
      "✓ K-Fold CV optimization results saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 2.5: Run Hyperparameter Optimization with K-Fold CV\n",
    "\n",
    "print(\"Starting K-Fold Cross-Validation hyperparameter optimization for TF-IDF + FFNN...\")\n",
    "print(\"Using 3-fold CV for robust hyperparameter selection\")\n",
    "print(\"This will take 20-40 minutes...\\n\")\n",
    "\n",
    "# Create Optuna study\n",
    "study_ffnn = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=TPESampler(seed=SEED),\n",
    "    study_name='tfidf_ffnn_kfold_optimization'\n",
    ")\n",
    "\n",
    "# Optimize with k-fold CV\n",
    "study_ffnn.optimize(objective_ffnn_kfold, n_trials=15, show_progress_bar=True)\n",
    "\n",
    "# Best parameters\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"K-FOLD CV OPTIMIZATION COMPLETE - TF-IDF + FFNN\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best mean CV accuracy: {study_ffnn.best_value:.2f}%\")\n",
    "print(f\"\\nBest hyperparameters:\")\n",
    "for key, value in study_ffnn.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Save study results\n",
    "os.makedirs('models/tfidf_ffnn', exist_ok=True)\n",
    "with open('models/tfidf_ffnn/optuna_study_kfold.pkl', 'wb') as f:\n",
    "    pickle.dump(study_ffnn, f)\n",
    "print(\"\\n✓ K-Fold CV optimization results saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06ea7eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final TF-IDF + FFNN model with best hyperparameters...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]: 100%|██████████| 750/750 [00:13<00:00, 55.79it/s, loss=0.1832]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.3527, Train Acc=84.03% | Val Loss=0.2603, Val Acc=89.26%\n",
      "  ✓ New best model saved to models/tfidf_ffnn/best_model.pt (Val Acc: 89.26%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|██████████| 750/750 [00:09<00:00, 75.25it/s, loss=0.1938] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1891, Train Acc=92.87% | Val Loss=0.2723, Val Acc=88.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|██████████| 750/750 [00:10<00:00, 70.39it/s, loss=0.1279] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1042, Train Acc=96.40% | Val Loss=0.3190, Val Acc=88.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|██████████| 750/750 [00:09<00:00, 78.51it/s, loss=0.0400] \n",
      "Epoch 4/30 [Train]: 100%|██████████| 750/750 [00:09<00:00, 78.51it/s, loss=0.0400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.0508, Train Acc=98.40% | Val Loss=0.3830, Val Acc=87.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|██████████| 750/750 [00:14<00:00, 50.29it/s, loss=0.0356]\n",
      "Epoch 5/30 [Train]: 100%|██████████| 750/750 [00:14<00:00, 50.29it/s, loss=0.0356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.0288, Train Acc=99.17% | Val Loss=0.4313, Val Acc=87.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|██████████| 750/750 [00:11<00:00, 63.86it/s, loss=0.0050] \n",
      "Epoch 6/30 [Train]: 100%|██████████| 750/750 [00:11<00:00, 63.86it/s, loss=0.0050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.0211, Train Acc=99.33% | Val Loss=0.4624, Val Acc=87.96%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "\n",
      "======================================================================\n",
      "TF-IDF + FFNN TRAINING COMPLETE\n",
      "======================================================================\n",
      "Best validation accuracy: 89.26%\n",
      "\n",
      "✓ Model saved to: models/tfidf_ffnn/\n"
     ]
    }
   ],
   "source": [
    "## 2.6: Train Final FFNN Model with Best Hyperparameters\n",
    "\n",
    "print(\"Training final TF-IDF + FFNN model with best hyperparameters...\\n\")\n",
    "\n",
    "best_params = study_ffnn.best_params\n",
    "\n",
    "# Create final model\n",
    "final_ffnn_model = FFNNClassifier(\n",
    "    input_dim=X_train_tfidf.shape[1],\n",
    "    hidden_dims=[best_params['hidden_dim1'], best_params['hidden_dim2']],\n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.FloatTensor(X_train_tfidf),\n",
    "    torch.LongTensor(train_labels)\n",
    ")\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.FloatTensor(X_val_tfidf),\n",
    "    torch.LongTensor(val_labels)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_params['batch_size'])\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = optim.Adam(final_ffnn_model.parameters(), lr=best_params['learning_rate'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train full model\n",
    "history_ffnn, best_val_acc = train_ffnn(\n",
    "    final_ffnn_model, train_loader, val_loader, optimizer, criterion,\n",
    "    num_epochs=30, patience=5, device=device, save_path='models/tfidf_ffnn/best_model.pt'\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "with open('models/tfidf_ffnn/training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history_ffnn, f)\n",
    "\n",
    "# Save hyperparameters\n",
    "with open('models/tfidf_ffnn/hyperparameters.json', 'w') as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TF-IDF + FFNN TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(\"\\n✓ Model saved to: models/tfidf_ffnn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "562b749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading E5 embedding model...\n",
      "This will download ~400MB on first run...\n",
      "\n",
      "✓ Loaded: intfloat/e5-small-v2\n",
      "  Embedding dimension: 384\n",
      "\n",
      "Generating embeddings...\n",
      "This may take 5-10 minutes...\n",
      "\n",
      "✓ Loaded: intfloat/e5-small-v2\n",
      "  Embedding dimension: 384\n",
      "\n",
      "Generating embeddings...\n",
      "This may take 5-10 minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 750/750 [02:06<00:00,  5.94it/s]\n",
      "\n",
      "Batches: 100%|██████████| 188/188 [00:34<00:00,  5.45it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Embeddings generated:\n",
      "  Train shape: (48000, 384)\n",
      "  Val shape:   (12000, 384)\n",
      "\n",
      "✓ Embeddings saved\n"
     ]
    }
   ],
   "source": [
    "## 3.1: Generate E5 Embeddings\n",
    "\n",
    "print(\"Loading E5 embedding model...\")\n",
    "print(\"This will download ~400MB on first run...\\n\")\n",
    "\n",
    "# Load E5 model (or use MiniLM as alternative)\n",
    "# E5 is stronger but larger, MiniLM is faster\n",
    "embedding_model_name = 'intfloat/e5-small-v2'  # or 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "embedding_model = SentenceTransformer(embedding_model_name, device=device)\n",
    "\n",
    "print(f\"✓ Loaded: {embedding_model_name}\")\n",
    "print(f\"  Embedding dimension: {embedding_model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"\\nGenerating embeddings...\")\n",
    "print(\"This may take 5-10 minutes...\\n\")\n",
    "\n",
    "# For E5, prefix with \"query: \" for better performance\n",
    "if 'e5' in embedding_model_name.lower():\n",
    "    train_texts_prefixed = [f\"query: {text}\" for text in train_texts]\n",
    "    val_texts_prefixed = [f\"query: {text}\" for text in val_texts]\n",
    "else:\n",
    "    train_texts_prefixed = train_texts\n",
    "    val_texts_prefixed = val_texts\n",
    "\n",
    "# Generate embeddings in batches\n",
    "X_train_embeddings = embedding_model.encode(\n",
    "    train_texts_prefixed,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "X_val_embeddings = embedding_model.encode(\n",
    "    val_texts_prefixed,\n",
    "    batch_size=64,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Embeddings generated:\")\n",
    "print(f\"  Train shape: {X_train_embeddings.shape}\")\n",
    "print(f\"  Val shape:   {X_val_embeddings.shape}\")\n",
    "\n",
    "# Save embeddings (for faster re-runs)\n",
    "np.save('models/e5_classifier/train_embeddings.npy', X_train_embeddings)\n",
    "np.save('models/e5_classifier/val_embeddings.npy', X_val_embeddings)\n",
    "print(\"\\n✓ Embeddings saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42c9b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embedding classifier class defined\n"
     ]
    }
   ],
   "source": [
    "## 3.2: Define Classifier Head for Embeddings\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    \"\"\"Simple classifier head for pre-computed embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_dim, hidden_dim, dropout_rate=0.3):\n",
    "        super(EmbeddingClassifier, self).__init__()\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, 2)  # Binary classification\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "print(\"✓ Embedding classifier class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d39577f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 01:32:34,384] A new study created in memory with name: embedding_classifier_kfold_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting K-Fold CV hyperparameter optimization for E5 classifier...\n",
      "Using 3-fold CV for robust hyperparameter selection\n",
      "This will take 15-25 minutes...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 0] Testing: hidden=128, dropout=0.485, lr=2.91e-03, batch=32\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:16<00:00, 76.76it/s, loss=0.1688]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:16<00:00, 76.76it/s, loss=0.1688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2164, Train Acc=91.72% | Val Loss=0.1602, Val Acc=93.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:24<00:00, 50.40it/s, loss=0.2907]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:24<00:00, 50.40it/s, loss=0.2907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2223, Train Acc=91.31% | Val Loss=0.1519, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:20<00:00, 60.39it/s, loss=0.2041]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.2234, Train Acc=91.25% | Val Loss=0.1600, Val Acc=94.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:27<00:00, 44.86it/s, loss=0.1895]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:27<00:00, 44.86it/s, loss=0.1895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.2102, Train Acc=91.66% | Val Loss=0.1620, Val Acc=93.50%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=94.19%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 67.44it/s, loss=0.1271]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2200, Train Acc=91.66% | Val Loss=0.1678, Val Acc=93.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 72.01it/s, loss=0.1973]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 72.01it/s, loss=0.1973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2123, Train Acc=91.91% | Val Loss=0.1613, Val Acc=93.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 58.33it/s, loss=0.1679]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 58.33it/s, loss=0.1679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.2093, Train Acc=91.92% | Val Loss=0.1504, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:19<00:00, 65.57it/s, loss=0.2427]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:19<00:00, 65.57it/s, loss=0.2427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.2070, Train Acc=92.11% | Val Loss=0.1594, Val Acc=93.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 79.15it/s, loss=0.2191]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 79.15it/s, loss=0.2191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.2067, Train Acc=91.99% | Val Loss=0.1668, Val Acc=92.94%\n",
      "\n",
      "Early stopping triggered after 5 epochs\n",
      "Acc=94.19%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:23<00:00, 53.41it/s, loss=0.2113]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2268, Train Acc=91.22% | Val Loss=0.1802, Val Acc=92.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:24<00:00, 50.11it/s, loss=0.1604]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2134, Train Acc=91.44% | Val Loss=0.1637, Val Acc=93.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:16<00:00, 75.70it/s, loss=0.3366]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.2118, Train Acc=91.42% | Val Loss=0.1601, Val Acc=93.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:19<00:00, 64.41it/s, loss=0.1643]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:19<00:00, 64.41it/s, loss=0.1643]\n",
      "Best trial: 0. Best value: 94.1:   8%|▊         | 1/12 [05:18<58:26, 318.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.2258, Train Acc=90.32% | Val Loss=0.1645, Val Acc=93.72%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=93.92%\n",
      "  → Mean CV Accuracy: 94.10% (±0.13%)\n",
      "[I 2025-11-10 01:37:53,130] Trial 0 finished with value: 94.10000000000001 and parameters: {'hidden_dim': 128, 'dropout_rate': 0.4852142919229748, 'learning_rate': 0.0029106359131330704, 'batch_size': 32}. Best is trial 0 with value: 94.10000000000001.\n",
      "\n",
      "[Trial 1] Testing: hidden=64, dropout=0.460, lr=1.59e-03, batch=128\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 50.09it/s, loss=0.2467]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1927, Train Acc=92.71% | Val Loss=0.1603, Val Acc=93.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 45.99it/s, loss=0.2075]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 45.99it/s, loss=0.2075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1757, Train Acc=93.44% | Val Loss=0.1511, Val Acc=94.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 45.25it/s, loss=0.1285]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 45.25it/s, loss=0.1285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1752, Train Acc=93.48% | Val Loss=0.1529, Val Acc=94.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 43.44it/s, loss=0.1410]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1713, Train Acc=93.60% | Val Loss=0.1510, Val Acc=94.18%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=94.32%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 40.32it/s, loss=0.1630]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 40.32it/s, loss=0.1630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1963, Train Acc=92.61% | Val Loss=0.1608, Val Acc=93.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 45.70it/s, loss=0.1507]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1796, Train Acc=93.40% | Val Loss=0.1503, Val Acc=94.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 68.04it/s, loss=0.1041]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 68.04it/s, loss=0.1041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1766, Train Acc=93.51% | Val Loss=0.1525, Val Acc=94.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 57.76it/s, loss=0.1939]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 57.76it/s, loss=0.1939]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1771, Train Acc=93.47% | Val Loss=0.1495, Val Acc=94.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 66.77it/s, loss=0.1926]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1730, Train Acc=93.68% | Val Loss=0.1529, Val Acc=93.96%\n",
      "\n",
      "Early stopping triggered after 5 epochs\n",
      "Acc=94.23%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 77.63it/s, loss=0.1937]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 77.63it/s, loss=0.1937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1931, Train Acc=92.66% | Val Loss=0.1584, Val Acc=94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 92.61it/s, loss=0.1777] \n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 92.61it/s, loss=0.1777] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1696, Train Acc=93.53% | Val Loss=0.1562, Val Acc=94.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 72.51it/s, loss=0.1877]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 72.51it/s, loss=0.1877]\n",
      "Best trial: 1. Best value: 94.2217:  17%|█▋        | 2/12 [06:40<29:52, 179.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1695, Train Acc=93.59% | Val Loss=0.1654, Val Acc=93.53%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=94.11%\n",
      "  → Mean CV Accuracy: 94.22% (±0.09%)\n",
      "[I 2025-11-10 01:39:14,759] Trial 1 finished with value: 94.22166666666668 and parameters: {'hidden_dim': 64, 'dropout_rate': 0.45985284373248053, 'learning_rate': 0.0015930522616241021, 'batch_size': 128}. Best is trial 1 with value: 94.22166666666668.\n",
      "\n",
      "[Trial 2] Testing: hidden=224, dropout=0.264, lr=2.31e-04, batch=128\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 68.27it/s, loss=0.3238]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 68.27it/s, loss=0.3238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1953, Train Acc=92.47% | Val Loss=0.1778, Val Acc=93.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 86.04it/s, loss=0.2358]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1615, Train Acc=93.87% | Val Loss=0.1574, Val Acc=94.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 75.55it/s, loss=0.1507]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 75.55it/s, loss=0.1507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1566, Train Acc=94.02% | Val Loss=0.1530, Val Acc=93.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 74.73it/s, loss=0.1738]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 74.73it/s, loss=0.1738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1538, Train Acc=94.09% | Val Loss=0.1541, Val Acc=93.98%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=94.16%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 53.42it/s, loss=0.0938]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 53.42it/s, loss=0.0938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1955, Train Acc=92.52% | Val Loss=0.1556, Val Acc=93.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 50.47it/s, loss=0.1639]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 50.47it/s, loss=0.1639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1627, Train Acc=93.86% | Val Loss=0.1556, Val Acc=93.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 102.07it/s, loss=0.1331]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1582, Train Acc=94.12% | Val Loss=0.1509, Val Acc=94.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 63.50it/s, loss=0.1475]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 63.50it/s, loss=0.1475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1549, Train Acc=94.08% | Val Loss=0.1493, Val Acc=94.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 67.66it/s, loss=0.1588]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 67.66it/s, loss=0.1588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1518, Train Acc=94.17% | Val Loss=0.1523, Val Acc=93.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 66.60it/s, loss=0.1280]\n",
      "Epoch 6/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 66.60it/s, loss=0.1280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1517, Train Acc=94.26% | Val Loss=0.1487, Val Acc=94.20%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.24%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 63.76it/s, loss=0.0893]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1930, Train Acc=92.48% | Val Loss=0.1608, Val Acc=93.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 72.59it/s, loss=0.1400]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 72.59it/s, loss=0.1400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1593, Train Acc=93.92% | Val Loss=0.1673, Val Acc=93.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.25it/s, loss=0.1711]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1568, Train Acc=93.99% | Val Loss=0.1563, Val Acc=94.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 54.00it/s, loss=0.1513]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 54.00it/s, loss=0.1513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1528, Train Acc=94.14% | Val Loss=0.1550, Val Acc=94.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 86.70it/s, loss=0.1482]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 86.70it/s, loss=0.1482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1508, Train Acc=94.26% | Val Loss=0.1553, Val Acc=94.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]:   0%|          | 0/312 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 54.89it/s, loss=0.1523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1488, Train Acc=94.20% | Val Loss=0.1537, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 62.86it/s, loss=0.1084]\n",
      "Epoch 7/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 62.86it/s, loss=0.1084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.1478, Train Acc=94.33% | Val Loss=0.1543, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 41.07it/s, loss=0.1075]\n",
      "Epoch 8/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 41.07it/s, loss=0.1075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.1449, Train Acc=94.30% | Val Loss=0.1539, Val Acc=94.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 48.99it/s, loss=0.3749]\n",
      "Epoch 9/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 48.99it/s, loss=0.3749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.1464, Train Acc=94.27% | Val Loss=0.1562, Val Acc=94.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 38.01it/s, loss=0.1129]\n",
      "Epoch 10/10 [Train]: 100%|██████████| 312/312 [00:08<00:00, 38.01it/s, loss=0.1129]\n",
      "Best trial: 1. Best value: 94.2217:  25%|██▌       | 3/12 [08:49<23:27, 156.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.1433, Train Acc=94.44% | Val Loss=0.1560, Val Acc=94.20%\n",
      "Acc=94.20%\n",
      "  → Mean CV Accuracy: 94.20% (±0.03%)\n",
      "[I 2025-11-10 01:41:23,917] Trial 2 finished with value: 94.20166666666665 and parameters: {'hidden_dim': 224, 'dropout_rate': 0.26370173320348284, 'learning_rate': 0.0002310201887845295, 'batch_size': 128}. Best is trial 1 with value: 94.22166666666668.\n",
      "\n",
      "[Trial 3] Testing: hidden=160, dropout=0.287, lr=1.67e-03, batch=128\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.58it/s, loss=0.2324]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.58it/s, loss=0.2324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1787, Train Acc=93.09% | Val Loss=0.1710, Val Acc=93.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 83.56it/s, loss=0.1498]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 83.56it/s, loss=0.1498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1674, Train Acc=93.72% | Val Loss=0.1576, Val Acc=93.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 93.19it/s, loss=0.1722]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 93.19it/s, loss=0.1722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1649, Train Acc=93.76% | Val Loss=0.1733, Val Acc=92.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 89.49it/s, loss=0.1571]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 89.49it/s, loss=0.1571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1630, Train Acc=93.81% | Val Loss=0.1498, Val Acc=94.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 57.41it/s, loss=0.1666] \n",
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 57.41it/s, loss=0.1666] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1634, Train Acc=93.82% | Val Loss=0.1515, Val Acc=94.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 55.07it/s, loss=0.2132]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1636, Train Acc=93.74% | Val Loss=0.1500, Val Acc=94.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 47.46it/s, loss=0.1438]\n",
      "Epoch 7/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 47.46it/s, loss=0.1438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.1602, Train Acc=93.95% | Val Loss=0.1515, Val Acc=94.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 49.98it/s, loss=0.1367]\n",
      "Epoch 8/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 49.98it/s, loss=0.1367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.1605, Train Acc=94.00% | Val Loss=0.1488, Val Acc=94.29%\n",
      "\n",
      "Early stopping triggered after 8 epochs\n",
      "Acc=94.34%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 59.28it/s, loss=0.1546]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1795, Train Acc=93.28% | Val Loss=0.1562, Val Acc=93.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 45.64it/s, loss=0.2478]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 45.64it/s, loss=0.2478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1673, Train Acc=93.65% | Val Loss=0.2037, Val Acc=91.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 52.82it/s, loss=0.1496]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1686, Train Acc=93.56% | Val Loss=0.1582, Val Acc=93.93%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=93.97%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.75it/s, loss=0.1531] \n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.75it/s, loss=0.1531] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1789, Train Acc=93.08% | Val Loss=0.2096, Val Acc=91.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 81.85it/s, loss=0.1178]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 81.85it/s, loss=0.1178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1631, Train Acc=93.71% | Val Loss=0.1569, Val Acc=94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 79.90it/s, loss=0.2067]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1617, Train Acc=93.86% | Val Loss=0.1550, Val Acc=94.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 61.02it/s, loss=0.2805]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 61.02it/s, loss=0.2805]\n",
      "Best trial: 1. Best value: 94.2217:  33%|███▎      | 4/12 [10:20<17:25, 130.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1613, Train Acc=93.80% | Val Loss=0.1562, Val Acc=94.11%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=94.11%\n",
      "  → Mean CV Accuracy: 94.14% (±0.15%)\n",
      "[I 2025-11-10 01:42:55,188] Trial 3 finished with value: 94.14 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.2873687420594126, 'learning_rate': 0.0016738085788752138, 'batch_size': 128}. Best is trial 1 with value: 94.22166666666668.\n",
      "\n",
      "[Trial 4] Testing: hidden=160, dropout=0.436, lr=2.51e-04, batch=64\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 54.32it/s, loss=0.2298]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 54.32it/s, loss=0.2298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1970, Train Acc=92.56% | Val Loss=0.1565, Val Acc=94.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.16it/s, loss=0.1923]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1699, Train Acc=93.50% | Val Loss=0.1699, Val Acc=93.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 69.03it/s, loss=0.1716]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 69.03it/s, loss=0.1716]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1669, Train Acc=93.65% | Val Loss=0.1515, Val Acc=94.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.37it/s, loss=0.1313] \n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.37it/s, loss=0.1313] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1641, Train Acc=93.82% | Val Loss=0.1500, Val Acc=94.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 75.77it/s, loss=0.2283]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1633, Train Acc=93.83% | Val Loss=0.1543, Val Acc=93.94%\n",
      "\n",
      "Early stopping triggered after 5 epochs\n",
      "Acc=94.39%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 83.47it/s, loss=0.1329]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 83.47it/s, loss=0.1329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1958, Train Acc=92.73% | Val Loss=0.1563, Val Acc=94.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 79.36it/s, loss=0.1427]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 79.36it/s, loss=0.1427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1694, Train Acc=93.77% | Val Loss=0.1530, Val Acc=94.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.88it/s, loss=0.1117]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.88it/s, loss=0.1117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1661, Train Acc=93.75% | Val Loss=0.1514, Val Acc=94.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 87.38it/s, loss=0.0918] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1625, Train Acc=93.90% | Val Loss=0.1511, Val Acc=94.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 75.36it/s, loss=0.3047]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1629, Train Acc=93.82% | Val Loss=0.1506, Val Acc=94.16%\n",
      "\n",
      "Early stopping triggered after 5 epochs\n",
      "Acc=94.18%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 80.86it/s, loss=0.1688]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 80.86it/s, loss=0.1688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1953, Train Acc=92.32% | Val Loss=0.1610, Val Acc=94.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 53.81it/s, loss=0.1374]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 53.81it/s, loss=0.1374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1700, Train Acc=93.42% | Val Loss=0.1579, Val Acc=94.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 84.75it/s, loss=0.0874]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 84.75it/s, loss=0.0874]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1634, Train Acc=93.78% | Val Loss=0.1577, Val Acc=93.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 61.31it/s, loss=0.0958] \n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 61.31it/s, loss=0.0958] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1600, Train Acc=93.94% | Val Loss=0.1545, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 52.84it/s, loss=0.1249]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1605, Train Acc=93.93% | Val Loss=0.1613, Val Acc=93.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.53it/s, loss=0.1040]\n",
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.53it/s, loss=0.1040]\n",
      "Best trial: 4. Best value: 94.255:  42%|████▏     | 5/12 [13:14<17:03, 146.19s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1571, Train Acc=93.90% | Val Loss=0.1550, Val Acc=94.17%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.19%\n",
      "  → Mean CV Accuracy: 94.25% (±0.10%)\n",
      "[I 2025-11-10 01:45:48,879] Trial 4 finished with value: 94.255 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.43555278841790407, 'learning_rate': 0.00025081156860452336, 'batch_size': 64}. Best is trial 4 with value: 94.255.\n",
      "\n",
      "[Trial 5] Testing: hidden=192, dropout=0.251, lr=1.35e-04, batch=64\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 49.88it/s, loss=0.0798]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 49.88it/s, loss=0.0798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2041, Train Acc=92.24% | Val Loss=0.1565, Val Acc=94.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 101.27it/s, loss=0.1539]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 101.27it/s, loss=0.1539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1668, Train Acc=93.67% | Val Loss=0.1536, Val Acc=94.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 70.79it/s, loss=0.2117]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 70.79it/s, loss=0.2117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1599, Train Acc=93.92% | Val Loss=0.1604, Val Acc=93.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 89.20it/s, loss=0.1410] \n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 89.20it/s, loss=0.1410] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1586, Train Acc=93.96% | Val Loss=0.1510, Val Acc=94.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 86.91it/s, loss=0.0787]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 86.91it/s, loss=0.0787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1562, Train Acc=94.04% | Val Loss=0.1497, Val Acc=94.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 48.44it/s, loss=0.1289]\n",
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 48.44it/s, loss=0.1289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1554, Train Acc=94.06% | Val Loss=0.1508, Val Acc=94.14%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.39%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 60.33it/s, loss=0.3206]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1967, Train Acc=92.53% | Val Loss=0.1551, Val Acc=93.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 91.15it/s, loss=0.2699]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 91.15it/s, loss=0.2699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1656, Train Acc=93.62% | Val Loss=0.1510, Val Acc=94.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 83.14it/s, loss=0.2234]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 83.14it/s, loss=0.2234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1599, Train Acc=93.85% | Val Loss=0.1509, Val Acc=94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 91.12it/s, loss=0.0896] \n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 91.12it/s, loss=0.0896] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1582, Train Acc=94.06% | Val Loss=0.1500, Val Acc=94.14%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=94.16%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.33it/s, loss=0.1043]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.33it/s, loss=0.1043]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1970, Train Acc=92.39% | Val Loss=0.1691, Val Acc=93.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:05<00:00, 106.73it/s, loss=0.1301]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:05<00:00, 106.73it/s, loss=0.1301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1655, Train Acc=93.70% | Val Loss=0.1574, Val Acc=94.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 75.24it/s, loss=0.1629]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1575, Train Acc=94.03% | Val Loss=0.1579, Val Acc=94.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]:   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.44it/s, loss=0.1325]\n",
      "Best trial: 4. Best value: 94.255:  50%|█████     | 6/12 [15:38<14:32, 145.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1551, Train Acc=94.06% | Val Loss=0.1562, Val Acc=94.11%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=94.14%\n",
      "  → Mean CV Accuracy: 94.23% (±0.12%)\n",
      "[I 2025-11-10 01:48:12,612] Trial 5 finished with value: 94.23166666666667 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.2511572371061875, 'learning_rate': 0.00013492834268013249, 'batch_size': 64}. Best is trial 4 with value: 94.255.\n",
      "\n",
      "[Trial 6] Testing: hidden=128, dropout=0.229, lr=2.34e-03, batch=128\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 80.35it/s, loss=0.1200]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 80.35it/s, loss=0.1200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1780, Train Acc=93.20% | Val Loss=0.1693, Val Acc=93.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 93.58it/s, loss=0.2621] \n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 93.58it/s, loss=0.2621] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1698, Train Acc=93.50% | Val Loss=0.1504, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 92.32it/s, loss=0.0843]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1650, Train Acc=93.69% | Val Loss=0.1501, Val Acc=94.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 80.76it/s, loss=0.1975]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 80.76it/s, loss=0.1975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1614, Train Acc=93.93% | Val Loss=0.1511, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 79.85it/s, loss=0.1172]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 79.85it/s, loss=0.1172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1596, Train Acc=94.05% | Val Loss=0.1526, Val Acc=93.97%\n",
      "\n",
      "Early stopping triggered after 5 epochs\n",
      "Acc=94.32%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 72.91it/s, loss=0.1383]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 72.91it/s, loss=0.1383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1781, Train Acc=93.22% | Val Loss=0.1631, Val Acc=93.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 70.37it/s, loss=0.1688]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 70.37it/s, loss=0.1688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1679, Train Acc=93.63% | Val Loss=0.1523, Val Acc=94.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 75.80it/s, loss=0.2127]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 75.80it/s, loss=0.2127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1634, Train Acc=93.83% | Val Loss=0.1614, Val Acc=93.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 83.49it/s, loss=0.1370]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 83.49it/s, loss=0.1370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1610, Train Acc=93.82% | Val Loss=0.1514, Val Acc=94.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 70.03it/s, loss=0.1152]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 70.03it/s, loss=0.1152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1604, Train Acc=93.92% | Val Loss=0.1501, Val Acc=94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 77.75it/s, loss=0.1417]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1601, Train Acc=94.07% | Val Loss=0.1528, Val Acc=93.90%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.22%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 63.83it/s, loss=0.1640]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1752, Train Acc=93.23% | Val Loss=0.1619, Val Acc=93.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 55.44it/s, loss=0.1829]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 55.44it/s, loss=0.1829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1627, Train Acc=93.76% | Val Loss=0.1661, Val Acc=93.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 43.67it/s, loss=0.1577]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 43.67it/s, loss=0.1577]\n",
      "Best trial: 4. Best value: 94.255:  58%|█████▊    | 7/12 [16:56<10:17, 123.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1645, Train Acc=93.74% | Val Loss=0.1618, Val Acc=93.62%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=93.81%\n",
      "  → Mean CV Accuracy: 94.12% (±0.22%)\n",
      "[I 2025-11-10 01:49:31,168] Trial 6 finished with value: 94.11666666666667 and parameters: {'hidden_dim': 128, 'dropout_rate': 0.22930163420191518, 'learning_rate': 0.0023359635026261607, 'batch_size': 128}. Best is trial 4 with value: 94.255.\n",
      "\n",
      "[Trial 7] Testing: hidden=64, dropout=0.473, lr=3.29e-04, batch=32\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 66.84it/s, loss=0.3579]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2095, Train Acc=92.33% | Val Loss=0.1523, Val Acc=94.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:23<00:00, 52.71it/s, loss=0.2171]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:23<00:00, 52.71it/s, loss=0.2171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1817, Train Acc=93.37% | Val Loss=0.1531, Val Acc=94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:22<00:00, 56.46it/s, loss=0.1004]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1805, Train Acc=93.30% | Val Loss=0.1501, Val Acc=94.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 78.48it/s, loss=0.0365]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1795, Train Acc=93.19% | Val Loss=0.1516, Val Acc=94.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 1250/1250 [00:23<00:00, 54.21it/s, loss=0.1165]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 1250/1250 [00:23<00:00, 54.21it/s, loss=0.1165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1786, Train Acc=93.38% | Val Loss=0.1520, Val Acc=93.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 68.09it/s, loss=0.1505]\n",
      "Epoch 6/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 68.09it/s, loss=0.1505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1757, Train Acc=93.37% | Val Loss=0.1510, Val Acc=94.28%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.28%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 67.75it/s, loss=0.4082]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2077, Train Acc=92.37% | Val Loss=0.1555, Val Acc=94.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 58.69it/s, loss=0.3815]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:21<00:00, 58.69it/s, loss=0.3815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1855, Train Acc=93.20% | Val Loss=0.1610, Val Acc=93.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:19<00:00, 63.51it/s, loss=0.1956]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:19<00:00, 63.51it/s, loss=0.1956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1823, Train Acc=93.28% | Val Loss=0.1520, Val Acc=94.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 78.64it/s, loss=0.1393]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1803, Train Acc=93.32% | Val Loss=0.1492, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 1250/1250 [00:25<00:00, 49.21it/s, loss=0.1233]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 1250/1250 [00:25<00:00, 49.21it/s, loss=0.1233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1782, Train Acc=93.50% | Val Loss=0.1572, Val Acc=93.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 1250/1250 [00:20<00:00, 61.85it/s, loss=0.0995]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1755, Train Acc=93.46% | Val Loss=0.1507, Val Acc=94.03%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.19%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1250/1250 [00:24<00:00, 51.38it/s, loss=0.0651]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2112, Train Acc=92.14% | Val Loss=0.1621, Val Acc=93.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 83.11it/s, loss=0.3259]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 1250/1250 [00:15<00:00, 83.11it/s, loss=0.3259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1816, Train Acc=93.09% | Val Loss=0.1617, Val Acc=94.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1250/1250 [00:20<00:00, 59.70it/s, loss=0.2258]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1779, Train Acc=93.31% | Val Loss=0.1560, Val Acc=94.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 69.95it/s, loss=0.0943]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 1250/1250 [00:17<00:00, 69.95it/s, loss=0.0943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1762, Train Acc=93.42% | Val Loss=0.1621, Val Acc=93.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 65.84it/s, loss=0.1854]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 1250/1250 [00:18<00:00, 65.84it/s, loss=0.1854]\n",
      "Best trial: 4. Best value: 94.255:  67%|██████▋   | 8/12 [23:43<14:15, 213.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1754, Train Acc=93.30% | Val Loss=0.1590, Val Acc=94.06%\n",
      "\n",
      "Early stopping triggered after 5 epochs\n",
      "Acc=94.15%\n",
      "  → Mean CV Accuracy: 94.21% (±0.06%)\n",
      "[I 2025-11-10 01:56:18,256] Trial 7 finished with value: 94.21 and parameters: {'hidden_dim': 64, 'dropout_rate': 0.47279612062363463, 'learning_rate': 0.00032927591344236165, 'batch_size': 32}. Best is trial 4 with value: 94.255.\n",
      "\n",
      "[Trial 8] Testing: hidden=160, dropout=0.255, lr=8.69e-03, batch=64\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 84.73it/s, loss=0.1245]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1914, Train Acc=92.67% | Val Loss=0.1625, Val Acc=93.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.41it/s, loss=0.2599]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.41it/s, loss=0.2599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1843, Train Acc=92.94% | Val Loss=0.1777, Val Acc=93.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 52.04it/s, loss=0.2637]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 52.04it/s, loss=0.2637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1800, Train Acc=93.22% | Val Loss=0.1572, Val Acc=93.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.66it/s, loss=0.1936]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1811, Train Acc=93.18% | Val Loss=0.1492, Val Acc=94.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 71.44it/s, loss=0.2407]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 71.44it/s, loss=0.2407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1757, Train Acc=93.31% | Val Loss=0.1549, Val Acc=94.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]:   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 90.44it/s, loss=0.1646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1750, Train Acc=93.35% | Val Loss=0.1530, Val Acc=93.92%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.24%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 86.55it/s, loss=0.0718]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1912, Train Acc=92.63% | Val Loss=0.1785, Val Acc=93.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 77.29it/s, loss=0.0999]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1826, Train Acc=93.12% | Val Loss=0.1546, Val Acc=94.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.42it/s, loss=0.1213]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1777, Train Acc=93.28% | Val Loss=0.1612, Val Acc=93.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.03it/s, loss=0.1665]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.03it/s, loss=0.1665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1726, Train Acc=93.48% | Val Loss=0.1702, Val Acc=92.89%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=94.18%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 59.03it/s, loss=0.1602]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1903, Train Acc=92.50% | Val Loss=0.1705, Val Acc=93.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.73it/s, loss=0.2064]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.73it/s, loss=0.2064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1796, Train Acc=93.00% | Val Loss=0.1648, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 56.70it/s, loss=0.2881]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 56.70it/s, loss=0.2881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1813, Train Acc=93.19% | Val Loss=0.1582, Val Acc=94.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 49.86it/s, loss=0.3474]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 49.86it/s, loss=0.3474]\n",
      "Best trial: 4. Best value: 94.255:  75%|███████▌  | 9/12 [26:15<09:43, 194.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1784, Train Acc=93.02% | Val Loss=0.1571, Val Acc=94.09%\n",
      "\n",
      "Early stopping triggered after 4 epochs\n",
      "Acc=94.19%\n",
      "  → Mean CV Accuracy: 94.20% (±0.03%)\n",
      "[I 2025-11-10 01:58:50,352] Trial 8 finished with value: 94.20333333333333 and parameters: {'hidden_dim': 160, 'dropout_rate': 0.2554563366576581, 'learning_rate': 0.00869299151113955, 'batch_size': 64}. Best is trial 4 with value: 94.255.\n",
      "\n",
      "[Trial 9] Testing: hidden=192, dropout=0.477, lr=1.50e-04, batch=128\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]:   0%|          | 0/312 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:07<00:00, 40.00it/s, loss=0.1516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2241, Train Acc=91.46% | Val Loss=0.1610, Val Acc=93.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 79.89it/s, loss=0.1151] \n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 79.89it/s, loss=0.1151] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1681, Train Acc=93.74% | Val Loss=0.1549, Val Acc=94.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 58.74it/s, loss=0.1397]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:05<00:00, 58.74it/s, loss=0.1397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1631, Train Acc=93.76% | Val Loss=0.1530, Val Acc=94.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 46.02it/s, loss=0.3318]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1609, Train Acc=93.92% | Val Loss=0.1625, Val Acc=93.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 46.92it/s, loss=0.1987]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1582, Train Acc=94.00% | Val Loss=0.1493, Val Acc=94.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 44.89it/s, loss=0.1269]\n",
      "Epoch 6/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 44.89it/s, loss=0.1269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1555, Train Acc=94.06% | Val Loss=0.1488, Val Acc=94.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 46.63it/s, loss=0.1516]\n",
      "Epoch 7/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 46.63it/s, loss=0.1516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.1546, Train Acc=94.11% | Val Loss=0.1494, Val Acc=94.36%\n",
      "\n",
      "Early stopping triggered after 7 epochs\n",
      "Acc=94.39%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 73.14it/s, loss=0.1928] \n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 73.14it/s, loss=0.1928] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2253, Train Acc=91.31% | Val Loss=0.1628, Val Acc=93.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 70.86it/s, loss=0.1649]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 70.86it/s, loss=0.1649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1692, Train Acc=93.66% | Val Loss=0.1561, Val Acc=93.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]:   0%|          | 0/312 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:06<00:00, 46.51it/s, loss=0.4632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1636, Train Acc=93.88% | Val Loss=0.1576, Val Acc=93.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 74.43it/s, loss=0.1458]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 74.43it/s, loss=0.1458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1609, Train Acc=93.99% | Val Loss=0.1516, Val Acc=94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.66it/s, loss=0.1101]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1579, Train Acc=94.02% | Val Loss=0.1514, Val Acc=94.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.37it/s, loss=0.2080]\n",
      "Epoch 6/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 69.37it/s, loss=0.2080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1561, Train Acc=94.15% | Val Loss=0.1519, Val Acc=94.11%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.25%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 77.47it/s, loss=0.1893]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 312/312 [00:04<00:00, 77.47it/s, loss=0.1893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2267, Train Acc=91.28% | Val Loss=0.1656, Val Acc=94.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 78.25it/s, loss=0.1077] \n",
      "Epoch 2/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 78.25it/s, loss=0.1077] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1661, Train Acc=93.61% | Val Loss=0.1638, Val Acc=93.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 90.65it/s, loss=0.1155] \n",
      "Epoch 3/10 [Train]: 100%|██████████| 312/312 [00:03<00:00, 90.65it/s, loss=0.1155] \n",
      "Best trial: 4. Best value: 94.255:  83%|████████▎ | 10/12 [28:00<05:33, 166.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1608, Train Acc=93.84% | Val Loss=0.1594, Val Acc=93.98%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=94.00%\n",
      "  → Mean CV Accuracy: 94.21% (±0.16%)\n",
      "[I 2025-11-10 02:00:34,815] Trial 9 finished with value: 94.21499999999999 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.47656227050693506, 'learning_rate': 0.00015030900645056822, 'batch_size': 128}. Best is trial 4 with value: 94.255.\n",
      "\n",
      "[Trial 10] Testing: hidden=256, dropout=0.402, lr=5.46e-04, batch=64\n",
      "  Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 96.29it/s, loss=0.0787]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 96.29it/s, loss=0.0787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1867, Train Acc=92.94% | Val Loss=0.1552, Val Acc=94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 99.50it/s, loss=0.1579]A\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 99.50it/s, loss=0.1579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1696, Train Acc=93.64% | Val Loss=0.1521, Val Acc=94.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 60.57it/s, loss=0.2102]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 60.57it/s, loss=0.2102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1683, Train Acc=93.66% | Val Loss=0.1509, Val Acc=94.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 92.48it/s, loss=0.1656]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 92.48it/s, loss=0.1656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1663, Train Acc=93.69% | Val Loss=0.1490, Val Acc=94.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 87.36it/s, loss=0.1181]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 87.36it/s, loss=0.1181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1651, Train Acc=93.68% | Val Loss=0.1491, Val Acc=94.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.15it/s, loss=0.1802]\n",
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.15it/s, loss=0.1802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1662, Train Acc=93.73% | Val Loss=0.1510, Val Acc=94.08%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.38%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 103.68it/s, loss=0.1237]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 103.68it/s, loss=0.1237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1856, Train Acc=93.04% | Val Loss=0.1623, Val Acc=93.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 65.54it/s, loss=0.1348]\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 65.54it/s, loss=0.1348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1725, Train Acc=93.54% | Val Loss=0.1547, Val Acc=94.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 65.37it/s, loss=0.1583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1694, Train Acc=93.58% | Val Loss=0.1525, Val Acc=94.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]:   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 65.37it/s, loss=0.2454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1677, Train Acc=93.72% | Val Loss=0.1538, Val Acc=93.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]:   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 59.55it/s, loss=0.2217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1687, Train Acc=93.69% | Val Loss=0.1492, Val Acc=94.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]:   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:10<00:00, 60.46it/s, loss=0.2285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1674, Train Acc=93.72% | Val Loss=0.1516, Val Acc=94.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Epoch 7/10 [Train]: 100%|██████████| 625/625 [00:05<00:00, 118.80it/s, loss=0.1264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.1653, Train Acc=93.78% | Val Loss=0.1511, Val Acc=94.06%\n",
      "\n",
      "Early stopping triggered after 7 epochs\n",
      "Acc=94.17%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 63.77it/s, loss=0.1078]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 63.77it/s, loss=0.1078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1842, Train Acc=92.93% | Val Loss=0.1639, Val Acc=93.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 50.27it/s, loss=0.2622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1679, Train Acc=93.69% | Val Loss=0.1619, Val Acc=93.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 80.34it/s, loss=0.1023]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 80.34it/s, loss=0.1023]\n",
      "Best trial: 4. Best value: 94.255:  92%|█████████▏| 11/12 [30:50<02:47, 167.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1632, Train Acc=93.69% | Val Loss=0.1669, Val Acc=93.55%\n",
      "\n",
      "Early stopping triggered after 3 epochs\n",
      "Acc=93.99%\n",
      "  → Mean CV Accuracy: 94.18% (±0.16%)\n",
      "[I 2025-11-10 02:03:24,501] Trial 10 finished with value: 94.18 and parameters: {'hidden_dim': 256, 'dropout_rate': 0.4024391203645334, 'learning_rate': 0.0005463331403485196, 'batch_size': 64}. Best is trial 4 with value: 94.255.\n",
      "\n",
      "[Trial 11] Testing: hidden=192, dropout=0.355, lr=1.07e-04, batch=64\n",
      "  Fold 1/3...   Fold 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 67.04it/s, loss=0.2316]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:09<00:00, 67.04it/s, loss=0.2316]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2142, Train Acc=91.93% | Val Loss=0.1580, Val Acc=94.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]:   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:13<00:00, 47.26it/s, loss=0.2130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1683, Train Acc=93.65% | Val Loss=0.1567, Val Acc=94.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 51.49it/s, loss=0.0654]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:12<00:00, 51.49it/s, loss=0.0654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1635, Train Acc=93.85% | Val Loss=0.1514, Val Acc=94.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 54.43it/s, loss=0.2106]\n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:11<00:00, 54.43it/s, loss=0.2106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1619, Train Acc=93.71% | Val Loss=0.1516, Val Acc=94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 77.66it/s, loss=0.2772] \n",
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 77.66it/s, loss=0.2772] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1585, Train Acc=93.89% | Val Loss=0.1492, Val Acc=94.25%\n",
      "\n",
      "Early stopping triggered after 5 epochs\n",
      "Acc=94.30%\n",
      "  Fold 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.53it/s, loss=0.1463]\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.53it/s, loss=0.1463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2151, Train Acc=91.59% | Val Loss=0.1574, Val Acc=93.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.44it/s, loss=0.0464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1679, Train Acc=93.68% | Val Loss=0.1533, Val Acc=94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.72it/s, loss=0.1601]\n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 82.72it/s, loss=0.1601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1644, Train Acc=93.84% | Val Loss=0.1522, Val Acc=94.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.06it/s, loss=0.1171]A\n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.06it/s, loss=0.1171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1615, Train Acc=93.95% | Val Loss=0.1509, Val Acc=94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]:   0%|          | 0/625 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 86.02it/s, loss=0.1280]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1606, Train Acc=93.86% | Val Loss=0.1492, Val Acc=94.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 89.67it/s, loss=0.1887]\n",
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:06<00:00, 89.67it/s, loss=0.1887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1571, Train Acc=94.12% | Val Loss=0.1491, Val Acc=94.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 72.26it/s, loss=0.1597]A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.1554, Train Acc=94.03% | Val Loss=0.1502, Val Acc=94.21%\n",
      "\n",
      "Early stopping triggered after 7 epochs\n",
      "Acc=94.28%\n",
      "  Fold 3/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Epoch 1/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 77.59it/s, loss=0.1660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.2176, Train Acc=91.60% | Val Loss=0.1636, Val Acc=93.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 80.39it/s, loss=0.1675][A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1677, Train Acc=93.64% | Val Loss=0.1614, Val Acc=93.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.96it/s, loss=0.1652] \n",
      "Epoch 3/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 76.96it/s, loss=0.1652] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1609, Train Acc=93.97% | Val Loss=0.1567, Val Acc=94.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Epoch 4/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 78.91it/s, loss=0.1920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1578, Train Acc=94.03% | Val Loss=0.1581, Val Acc=94.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 78.31it/s, loss=0.1753]\n",
      "Epoch 5/10 [Train]: 100%|██████████| 625/625 [00:07<00:00, 78.31it/s, loss=0.1753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1581, Train Acc=93.92% | Val Loss=0.1559, Val Acc=94.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 75.64it/s, loss=0.1089]\n",
      "Epoch 6/10 [Train]: 100%|██████████| 625/625 [00:08<00:00, 75.64it/s, loss=0.1089]\n",
      "Best trial: 4. Best value: 94.255: 100%|██████████| 12/12 [34:03<00:00, 170.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1537, Train Acc=94.16% | Val Loss=0.1587, Val Acc=94.08%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "Acc=94.12%\n",
      "  → Mean CV Accuracy: 94.23% (±0.08%)\n",
      "[I 2025-11-10 02:06:37,570] Trial 11 finished with value: 94.23333333333333 and parameters: {'hidden_dim': 192, 'dropout_rate': 0.3548125484709944, 'learning_rate': 0.00010744583847151158, 'batch_size': 64}. Best is trial 4 with value: 94.255.\n",
      "\n",
      "======================================================================\n",
      "K-FOLD CV OPTIMIZATION COMPLETE - E5 Embedding Classifier\n",
      "======================================================================\n",
      "Best mean CV accuracy: 94.25%\n",
      "\n",
      "Best hyperparameters:\n",
      "  hidden_dim: 160\n",
      "  dropout_rate: 0.43555278841790407\n",
      "  learning_rate: 0.00025081156860452336\n",
      "  batch_size: 64\n",
      "\n",
      "✓ K-Fold CV optimization results saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 3.3: Hyperparameter Optimization for Embedding Classifier with K-Fold CV\n",
    "\n",
    "def objective_embedding_kfold(trial):\n",
    "    \"\"\"Optuna objective for embedding classifier with K-Fold CV\"\"\"\n",
    "    \n",
    "    # Hyperparameters\n",
    "    hidden_dim = trial.suggest_int('hidden_dim', 64, 256, step=32)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    print(f\"\\n[Trial {trial.number}] Testing: hidden={hidden_dim}, \"\n",
    "          f\"dropout={dropout_rate:.3f}, lr={learning_rate:.2e}, batch={batch_size}\")\n",
    "    \n",
    "    # K-Fold Cross-Validation setup\n",
    "    n_folds = 3\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    # Combine train and val embeddings for k-fold\n",
    "    X_combined = np.vstack([X_train_embeddings, X_val_embeddings])\n",
    "    y_combined = np.array(train_labels + val_labels)\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_combined, y_combined)):\n",
    "        print(f\"  Fold {fold_idx+1}/{n_folds}...\", end=\" \")\n",
    "        \n",
    "        # Split data for this fold\n",
    "        X_fold_train = X_combined[train_idx]\n",
    "        y_fold_train = y_combined[train_idx]\n",
    "        X_fold_val = X_combined[val_idx]\n",
    "        y_fold_val = y_combined[val_idx]\n",
    "        \n",
    "        # Create fresh model for this fold\n",
    "        model = EmbeddingClassifier(\n",
    "            embedding_dim=X_train_embeddings.shape[1],\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_fold_train),\n",
    "            torch.LongTensor(y_fold_train)\n",
    "        )\n",
    "        val_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.FloatTensor(X_fold_val),\n",
    "            torch.LongTensor(y_fold_val)\n",
    "        )\n",
    "        \n",
    "        # Use drop_last=True to avoid BatchNorm issues with single-sample batches\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=False)\n",
    "        \n",
    "        # Optimizer and loss\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Train (reuse training function)\n",
    "        _, best_val_acc = train_ffnn(\n",
    "            model, train_loader, val_loader, optimizer, criterion,\n",
    "            num_epochs=10, patience=2, device=device, save_path=None\n",
    "        )\n",
    "        \n",
    "        fold_scores.append(best_val_acc)\n",
    "        print(f\"Acc={best_val_acc:.2f}%\")\n",
    "        \n",
    "        # Clean up to save memory\n",
    "        del model, optimizer, train_loader, val_loader\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    # Return mean accuracy across all folds\n",
    "    mean_acc = np.mean(fold_scores)\n",
    "    std_acc = np.std(fold_scores)\n",
    "    print(f\"  → Mean CV Accuracy: {mean_acc:.2f}% (±{std_acc:.2f}%)\")\n",
    "    \n",
    "    return mean_acc\n",
    "\n",
    "print(\"Starting K-Fold CV hyperparameter optimization for E5 classifier...\")\n",
    "print(\"Using 3-fold CV for robust hyperparameter selection\")\n",
    "print(\"This will take 15-25 minutes...\\n\")\n",
    "\n",
    "# Create study\n",
    "study_embedding = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=TPESampler(seed=SEED),\n",
    "    study_name='embedding_classifier_kfold_optimization'\n",
    ")\n",
    "\n",
    "# Optimize with k-fold CV\n",
    "study_embedding.optimize(objective_embedding_kfold, n_trials=12, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"K-FOLD CV OPTIMIZATION COMPLETE - E5 Embedding Classifier\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best mean CV accuracy: {study_embedding.best_value:.2f}%\")\n",
    "print(f\"\\nBest hyperparameters:\")\n",
    "for key, value in study_embedding.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Save study\n",
    "os.makedirs('models/e5_classifier', exist_ok=True)\n",
    "with open('models/e5_classifier/optuna_study_kfold.pkl', 'wb') as f:\n",
    "    pickle.dump(study_embedding, f)\n",
    "print(\"\\n✓ K-Fold CV optimization results saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65e34e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final E5 classifier with best hyperparameters...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]: 100%|██████████| 750/750 [00:07<00:00, 99.50it/s, loss=0.1811] \n",
      "Epoch 1/30 [Train]: 100%|██████████| 750/750 [00:07<00:00, 99.50it/s, loss=0.1811] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.1905, Train Acc=92.70% | Val Loss=0.1578, Val Acc=94.08%\n",
      "  ✓ New best model saved to models/e5_classifier/best_model.pt (Val Acc: 94.08%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|██████████| 750/750 [00:07<00:00, 98.17it/s, loss=0.1213] \n",
      "Epoch 2/30 [Train]: 100%|██████████| 750/750 [00:07<00:00, 98.17it/s, loss=0.1213] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.1683, Train Acc=93.70% | Val Loss=0.1601, Val Acc=93.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|██████████| 750/750 [00:10<00:00, 74.74it/s, loss=0.1040] \n",
      "Epoch 3/30 [Train]: 100%|██████████| 750/750 [00:10<00:00, 74.74it/s, loss=0.1040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.1653, Train Acc=93.76% | Val Loss=0.1533, Val Acc=93.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|██████████| 750/750 [00:09<00:00, 79.36it/s, loss=0.1303] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.1625, Train Acc=93.79% | Val Loss=0.1529, Val Acc=94.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|██████████| 750/750 [00:11<00:00, 63.30it/s, loss=0.1679] \n",
      "Epoch 5/30 [Train]: 100%|██████████| 750/750 [00:11<00:00, 63.30it/s, loss=0.1679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.1592, Train Acc=93.96% | Val Loss=0.1510, Val Acc=94.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|██████████| 750/750 [00:06<00:00, 110.45it/s, loss=0.1956]\n",
      "Epoch 6/30 [Train]: 100%|██████████| 750/750 [00:06<00:00, 110.45it/s, loss=0.1956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.1587, Train Acc=93.92% | Val Loss=0.1535, Val Acc=94.04%\n",
      "\n",
      "Early stopping triggered after 6 epochs\n",
      "\n",
      "======================================================================\n",
      "E5 EMBEDDING CLASSIFIER TRAINING COMPLETE\n",
      "======================================================================\n",
      "Best validation accuracy: 94.08%\n",
      "\n",
      "✓ Model saved to: models/e5_classifier/\n"
     ]
    }
   ],
   "source": [
    "## 3.4: Train Final E5 Classifier\n",
    "\n",
    "print(\"Training final E5 classifier with best hyperparameters...\\n\")\n",
    "\n",
    "best_params = study_embedding.best_params\n",
    "\n",
    "# Create final model\n",
    "final_embedding_model = EmbeddingClassifier(\n",
    "    embedding_dim=X_train_embeddings.shape[1],\n",
    "    hidden_dim=best_params['hidden_dim'],\n",
    "    dropout_rate=best_params['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.FloatTensor(X_train_embeddings),\n",
    "    torch.LongTensor(train_labels)\n",
    ")\n",
    "val_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.FloatTensor(X_val_embeddings),\n",
    "    torch.LongTensor(val_labels)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_params['batch_size'])\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = optim.Adam(final_embedding_model.parameters(), lr=best_params['learning_rate'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train\n",
    "history_embedding, best_val_acc = train_ffnn(\n",
    "    final_embedding_model, train_loader, val_loader, optimizer, criterion,\n",
    "    num_epochs=30, patience=5, device=device, save_path='models/e5_classifier/best_model.pt'\n",
    ")\n",
    "\n",
    "# Save everything\n",
    "with open('models/e5_classifier/training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history_embedding, f)\n",
    "\n",
    "with open('models/e5_classifier/hyperparameters.json', 'w') as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "\n",
    "# Save model name for later use\n",
    "with open('models/e5_classifier/embedding_model_name.txt', 'w') as f:\n",
    "    f.write(embedding_model_name)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"E5 EMBEDDING CLASSIFIER TRAINING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(\"\\n✓ Model saved to: models/e5_classifier/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53263974",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Model 3 - BERT Fine-Tuning with K-Fold CV Optimization\n",
    "\n",
    "Fine-tune BERT (bert-base-uncased) for sentiment classification.\n",
    "Uses K-Fold CV to find optimal hyperparameters for better performance.\n",
    "\n",
    "**Key Improvements:**\n",
    "- 2-fold stratified CV for hyperparameter search (faster than 3-fold for BERT)\n",
    "- Optimizes: learning rate, weight decay, warmup ratio, epochs, batch size\n",
    "- More robust than fixed hyperparameters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf04a95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BERT dataset class defined\n"
     ]
    }
   ],
   "source": [
    "## 4.1: Prepare BERT Dataset\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"Dataset class for BERT tokenization\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"✓ BERT dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a56fee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT model and tokenizer...\n",
      "This will download ~440MB on first run...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load tokenizer\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load model for sequence classification\u001b[39;00m\n\u001b[1;32m     12\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m AutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     13\u001b[0m     model_name,\n\u001b[1;32m     14\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     15\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "## 4.2: Load BERT Tokenizer and Model\n",
    "\n",
    "print(\"Loading BERT model and tokenizer...\")\n",
    "print(\"This will download ~440MB on first run...\\n\")\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load model for sequence classification\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "print(f\"✓ Loaded: {model_name}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in bert_model.parameters()):,}\")\n",
    "print(f\"  Trainable parameters: {sum(p.numel() for p in bert_model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa30694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tokenized datasets...\n",
      "This may take 2-3 minutes...\n",
      "\n",
      "✓ Datasets created:\n",
      "  Train: 48,000 samples\n",
      "  Val:   12,000 samples\n",
      "\n",
      "Sample tokenization:\n",
      "  Input IDs shape: torch.Size([256])\n",
      "  Attention mask shape: torch.Size([256])\n",
      "  Label: 0\n"
     ]
    }
   ],
   "source": [
    "## 4.3: Create BERT Datasets\n",
    "\n",
    "print(\"Creating tokenized datasets...\")\n",
    "print(\"This may take 2-3 minutes...\\n\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset_bert = SentimentDataset(\n",
    "    texts=train_texts,\n",
    "    labels=train_labels,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "val_dataset_bert = SentimentDataset(\n",
    "    texts=val_texts,\n",
    "    labels=val_labels,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "print(f\"✓ Datasets created:\")\n",
    "print(f\"  Train: {len(train_dataset_bert):,} samples\")\n",
    "print(f\"  Val:   {len(val_dataset_bert):,} samples\")\n",
    "\n",
    "# Test tokenization\n",
    "sample = train_dataset_bert[0]\n",
    "print(f\"\\nSample tokenization:\")\n",
    "print(f\"  Input IDs shape: {sample['input_ids'].shape}\")\n",
    "print(f\"  Attention mask shape: {sample['attention_mask'].shape}\")\n",
    "print(f\"  Label: {sample['labels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c774e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metrics function defined\n"
     ]
    }
   ],
   "source": [
    "## 4.4: Define Metrics for BERT Training\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute metrics for BERT evaluation\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='binary'\n",
    "    )\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "print(\"✓ Metrics function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e87829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 0: unexpected EOF while looking for matching `''\n",
      "/bin/bash: -c: line 1: syntax error: unexpected end of file\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install 'accelerate>={ACCELERATE_MIN_VERSION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-10 02:07:44,486] A new study created in memory with name: bert_kfold_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting K-Fold CV hyperparameter optimization for BERT...\n",
      "Using 2-fold CV for computational efficiency\n",
      "This will take 1-3 hours depending on your hardware...\n",
      "\n",
      "NOTE: You can reduce n_trials to 3-5 for faster testing\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 0] Testing: lr=1.83e-05, wd=0.095, warmup=0.15, epochs=3, batch=8\n",
      "  Fold 1/2...   Fold 1/2... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  0%|          | 0/8 [00:10<?, ?it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-11-10 02:07:55,203] Trial 0 failed with parameters: {'learning_rate': 1.827226177606625e-05, 'weight_decay': 0.09507143064099162, 'warmup_ratio': 0.146398788362281, 'num_epochs': 3, 'batch_size': 8} because of the following error: OutOfMemoryError('Caught OutOfMemoryError in replica 1 on device 1.\\nOriginal Traceback (most recent call last):\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 84, in _worker\\n    output = module(*input, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 1668, in forward\\n    outputs = self.bert(\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 1142, in forward\\n    encoder_outputs = self.encoder(\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 695, in forward\\n    layer_outputs = layer_module(\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 585, in forward\\n    self_attention_outputs = self.attention(\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 515, in forward\\n    self_outputs = self.self(\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 409, in forward\\n    value_layer = self.transpose_for_scores(self.value(current_states))\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\\n    return self._call_impl(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\\n    return forward_call(*args, **kwargs)\\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 117, in forward\\n    return F.linear(input, self.weight, self.bias)\\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 79.25 GiB of which 5.94 MiB is free. Process 2669594 has 77.63 GiB memory in use. Including non-PyTorch memory, this process has 1.59 GiB memory in use. Of the allocated memory 865.21 MiB is allocated by PyTorch, and 22.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_2846456/3660316517.py\", line 93, in objective_bert_kfold\n",
      "    fold_trainer.train()\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/trainer.py\", line 2123, in train\n",
      "    return inner_training_loop(\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/trainer.py\", line 2481, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/trainer.py\", line 3579, in training_step\n",
      "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/trainer.py\", line 3633, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 186, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\", line 201, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 109, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/_utils.py\", line 706, in reraise\n",
      "    raise exception\n",
      "torch.OutOfMemoryError: Caught OutOfMemoryError in replica 1 on device 1.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 84, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 1668, in forward\n",
      "    outputs = self.bert(\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 1142, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 695, in forward\n",
      "    layer_outputs = layer_module(\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 585, in forward\n",
      "    self_attention_outputs = self.attention(\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 515, in forward\n",
      "    self_outputs = self.self(\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 409, in forward\n",
      "    value_layer = self.transpose_for_scores(self.value(current_states))\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 117, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 79.25 GiB of which 5.94 MiB is free. Process 2669594 has 77.63 GiB memory in use. Including non-PyTorch memory, this process has 1.59 GiB memory in use. Of the allocated memory 865.21 MiB is allocated by PyTorch, and 22.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "[W 2025-11-10 02:07:55,217] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 84, in _worker\n    output = module(*input, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 1668, in forward\n    outputs = self.bert(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 1142, in forward\n    encoder_outputs = self.encoder(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 695, in forward\n    layer_outputs = layer_module(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 585, in forward\n    self_attention_outputs = self.attention(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 515, in forward\n    self_outputs = self.self(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 409, in forward\n    value_layer = self.transpose_for_scores(self.value(current_states))\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 79.25 GiB of which 5.94 MiB is free. Process 2669594 has 77.63 GiB memory in use. Including non-PyTorch memory, this process has 1.59 GiB memory in use. Of the allocated memory 865.21 MiB is allocated by PyTorch, and 22.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 131\u001b[0m\n\u001b[1;32m    124\u001b[0m study_bert \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    125\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    126\u001b[0m     sampler\u001b[38;5;241m=\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mSEED),\n\u001b[1;32m    127\u001b[0m     study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_kfold_optimization\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    128\u001b[0m )\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Optimize with k-fold CV (fewer trials due to computational cost)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[43mstudy_bert\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_bert_kfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mK-FOLD CV OPTIMIZATION COMPLETE - BERT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    257\u001b[0m ):\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[25], line 93\u001b[0m, in \u001b[0;36mobjective_bert_kfold\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     83\u001b[0m fold_trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     84\u001b[0m     model\u001b[38;5;241m=\u001b[39mfold_model,\n\u001b[1;32m     85\u001b[0m     args\u001b[38;5;241m=\u001b[39mfold_training_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m     90\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m \u001b[43mfold_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[1;32m     96\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m fold_trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/transformers/trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2479\u001b[0m )\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/transformers/trainer.py:3579\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3579\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3584\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3585\u001b[0m ):\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/transformers/trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:186\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    185\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 186\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:201\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:109\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    107\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 109\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/FYP-Research/.venv/lib/python3.8/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 84, in _worker\n    output = module(*input, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 1668, in forward\n    outputs = self.bert(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 1142, in forward\n    encoder_outputs = self.encoder(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 695, in forward\n    layer_outputs = layer_module(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 585, in forward\n    self_attention_outputs = self.attention(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 515, in forward\n    self_outputs = self.self(\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\", line 409, in forward\n    value_layer = self.transpose_for_scores(self.value(current_states))\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/home3/rudrapra001/FYP-Research/.venv/lib/python3.8/site-packages/torch/nn/modules/linear.py\", line 117, in forward\n    return F.linear(input, self.weight, self.bias)\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 1 has a total capacity of 79.25 GiB of which 5.94 MiB is free. Process 2669594 has 77.63 GiB memory in use. Including non-PyTorch memory, this process has 1.59 GiB memory in use. Of the allocated memory 865.21 MiB is allocated by PyTorch, and 22.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "## 4.5: BERT Hyperparameter Optimization with K-Fold CV\n",
    "\n",
    "def objective_bert_kfold(trial):\n",
    "    \"\"\"Optuna objective for BERT with K-Fold CV\n",
    "    \n",
    "    Uses stratified 2-fold CV (not 3-fold due to BERT's computational cost).\n",
    "    Optimizes key hyperparameters that affect BERT performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hyperparameters to optimize\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.0, 0.1)\n",
    "    warmup_ratio = trial.suggest_float('warmup_ratio', 0.0, 0.2)\n",
    "    num_epochs = trial.suggest_int('num_epochs', 2, 4)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16])\n",
    "    \n",
    "    print(f\"\\n[Trial {trial.number}] Testing: lr={learning_rate:.2e}, wd={weight_decay:.3f}, \"\n",
    "          f\"warmup={warmup_ratio:.2f}, epochs={num_epochs}, batch={batch_size}\")\n",
    "    \n",
    "    # Use 2-fold CV for BERT (computational efficiency)\n",
    "    n_folds = 2\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    fold_scores = []\n",
    "    \n",
    "    # Combine train and val for k-fold\n",
    "    combined_texts = train_texts + val_texts\n",
    "    combined_labels = train_labels + val_labels\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(combined_texts, combined_labels)):\n",
    "        print(f\"  Fold {fold_idx+1}/{n_folds}...\", end=\" \")\n",
    "        \n",
    "        # Create datasets for this fold\n",
    "        fold_train_texts = [combined_texts[i] for i in train_idx]\n",
    "        fold_train_labels = [combined_labels[i] for i in train_idx]\n",
    "        fold_val_texts = [combined_texts[i] for i in val_idx]\n",
    "        fold_val_labels = [combined_labels[i] for i in val_idx]\n",
    "        \n",
    "        fold_train_dataset = SentimentDataset(\n",
    "            texts=fold_train_texts,\n",
    "            labels=fold_train_labels,\n",
    "            tokenizer=tokenizer,\n",
    "            max_length=256\n",
    "        )\n",
    "        fold_val_dataset = SentimentDataset(\n",
    "            texts=fold_val_texts,\n",
    "            labels=fold_val_labels,\n",
    "            tokenizer=tokenizer,\n",
    "            max_length=256\n",
    "        )\n",
    "        \n",
    "        # Load fresh BERT model for this fold\n",
    "        fold_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            'bert-base-uncased',\n",
    "            num_labels=2,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False\n",
    "        )\n",
    "        \n",
    "        # Training arguments for this fold\n",
    "        fold_training_args = TrainingArguments(\n",
    "            output_dir=f'models/bert_finetuned/trial_{trial.number}_fold_{fold_idx}',\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=32,\n",
    "            warmup_ratio=warmup_ratio,\n",
    "            weight_decay=weight_decay,\n",
    "            learning_rate=learning_rate,\n",
    "            logging_steps=200,\n",
    "            evaluation_strategy='epoch',\n",
    "            save_strategy='epoch',\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='f1',\n",
    "            greater_is_better=True,\n",
    "            fp16=torch.cuda.is_available(),\n",
    "            seed=SEED,\n",
    "            report_to='none',  # Disable wandb/tensorboard during tuning\n",
    "            logging_dir=None\n",
    "        )\n",
    "        \n",
    "        # Create trainer\n",
    "        fold_trainer = Trainer(\n",
    "            model=fold_model,\n",
    "            args=fold_training_args,\n",
    "            train_dataset=fold_train_dataset,\n",
    "            eval_dataset=fold_val_dataset,\n",
    "            compute_metrics=compute_metrics,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        fold_trainer.train()\n",
    "        \n",
    "        # Evaluate\n",
    "        eval_results = fold_trainer.evaluate()\n",
    "        fold_f1 = eval_results['eval_f1']\n",
    "        fold_scores.append(fold_f1)\n",
    "        \n",
    "        print(f\"F1={fold_f1:.4f}\")\n",
    "        \n",
    "        # Clean up\n",
    "        del fold_model, fold_trainer\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "        # Remove temporary checkpoint directory\n",
    "        import shutil\n",
    "        if os.path.exists(f'models/bert_finetuned/trial_{trial.number}_fold_{fold_idx}'):\n",
    "            shutil.rmtree(f'models/bert_finetuned/trial_{trial.number}_fold_{fold_idx}')\n",
    "    \n",
    "    # Return mean F1 score across folds\n",
    "    mean_f1 = np.mean(fold_scores)\n",
    "    std_f1 = np.std(fold_scores)\n",
    "    print(f\"  → Mean CV F1: {mean_f1:.4f} (±{std_f1:.4f})\")\n",
    "    \n",
    "    return mean_f1\n",
    "\n",
    "print(\"Starting K-Fold CV hyperparameter optimization for BERT...\")\n",
    "print(\"Using 2-fold CV for computational efficiency\")\n",
    "print(\"This will take 1-3 hours depending on your hardware...\\n\")\n",
    "print(\"NOTE: You can reduce n_trials to 3-5 for faster testing\\n\")\n",
    "\n",
    "# Create study\n",
    "study_bert = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=TPESampler(seed=SEED),\n",
    "    study_name='bert_kfold_optimization'\n",
    ")\n",
    "\n",
    "# Optimize with k-fold CV (fewer trials due to computational cost)\n",
    "study_bert.optimize(objective_bert_kfold, n_trials=8, show_progress_bar=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"K-FOLD CV OPTIMIZATION COMPLETE - BERT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best mean CV F1: {study_bert.best_value:.4f}\")\n",
    "print(f\"\\nBest hyperparameters:\")\n",
    "for key, value in study_bert.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Save study results\n",
    "os.makedirs('models/bert_finetuned', exist_ok=True)\n",
    "with open('models/bert_finetuned/optuna_study_kfold.pkl', 'wb') as f:\n",
    "    pickle.dump(study_bert, f)\n",
    "\n",
    "# Save best params\n",
    "with open('models/bert_finetuned/best_hyperparameters.json', 'w') as f:\n",
    "    json.dump(study_bert.best_params, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ K-Fold CV optimization results saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.6: Train Final BERT Model with Best Hyperparameters\n",
    "\n",
    "print(\"\\nTraining final BERT model with best hyperparameters from K-Fold CV...\")\n",
    "print(\"This will take 30-60 minutes (or 2-4 hours on CPU)...\\n\")\n",
    "\n",
    "best_params = study_bert.best_params\n",
    "\n",
    "# Calculate warmup steps from warmup ratio\n",
    "total_steps = (len(train_dataset_bert) // best_params['batch_size']) * best_params['num_epochs']\n",
    "warmup_steps = int(total_steps * best_params['warmup_ratio'])\n",
    "\n",
    "print(f\"Using optimized hyperparameters:\")\n",
    "print(f\"  Learning rate: {best_params['learning_rate']:.2e}\")\n",
    "print(f\"  Weight decay: {best_params['weight_decay']:.3f}\")\n",
    "print(f\"  Warmup ratio: {best_params['warmup_ratio']:.2f} ({warmup_steps} steps)\")\n",
    "print(f\"  Epochs: {best_params['num_epochs']}\")\n",
    "print(f\"  Batch size: {best_params['batch_size']}\\n\")\n",
    "\n",
    "# Load fresh BERT model for final training\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "\n",
    "# Training arguments with optimized hyperparameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='models/bert_finetuned',\n",
    "    num_train_epochs=best_params['num_epochs'],\n",
    "    per_device_train_batch_size=best_params['batch_size'],\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=warmup_steps,\n",
    "    weight_decay=best_params['weight_decay'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    logging_dir='outputs/training_logs/bert',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_bert,\n",
    "    eval_dataset=val_dataset_bert,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# Train\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Save model\n",
    "trainer.save_model('models/bert_finetuned/final_model')\n",
    "tokenizer.save_pretrained('models/bert_finetuned/final_model')\n",
    "\n",
    "# Save training metrics\n",
    "with open('models/bert_finetuned/training_metrics.json', 'w') as f:\n",
    "    json.dump(train_result.metrics, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BERT FINE-TUNING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Training loss: {train_result.metrics['train_loss']:.4f}\")\n",
    "print(\"\\n✓ Model saved to: models/bert_finetuned/final_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.7: Evaluate BERT on Validation Set\n",
    "\n",
    "print(\"Evaluating BERT on validation set...\\n\")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"Validation Results:\")\n",
    "print(f\"  Accuracy:  {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"  F1 Score:  {eval_results['eval_f1']:.4f}\")\n",
    "print(f\"  Precision: {eval_results['eval_precision']:.4f}\")\n",
    "print(f\"  Recall:    {eval_results['eval_recall']:.4f}\")\n",
    "\n",
    "# Save evaluation results\n",
    "with open('models/bert_finetuned/validation_metrics.json', 'w') as f:\n",
    "    json.dump(eval_results, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Evaluation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9926151",
   "metadata": {},
   "source": [
    "---\n",
    "## ✅ Notebook 2 Complete!\n",
    "\n",
    "### What we accomplished:\n",
    "1. ✓ Trained TF-IDF + FFNN classifier with Optuna optimization\n",
    "2. ✓ Trained E5 embedding classifier with Optuna optimization\n",
    "3. ✓ Fine-tuned BERT for sentiment analysis\n",
    "4. ✓ Saved all models and hyperparameters\n",
    "5. ✓ Achieved strong validation performance on multi-domain data\n",
    "\n",
    "### Models Saved:\n",
    "- `models/tfidf_ffnn/` - TF-IDF + FFNN classifier\n",
    "- `models/e5_classifier/` - E5 embedding classifier\n",
    "- `models/bert_finetuned/` - Fine-tuned BERT model\n",
    "\n",
    "### Next Steps:\n",
    "→ **Notebook 3**: Evaluation & Domain Adaptation Analysis\n",
    "- Load all trained models\n",
    "- In-domain evaluation (IMDB + Yelp test sets)\n",
    "- **Cross-domain evaluation** (Amazon test set)\n",
    "- Performance comparison and visualization\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.8.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
